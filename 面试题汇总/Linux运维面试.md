# 自我介绍

	各位面试官好，我叫刘子川，毕业于西华大学，在Linux运维行业有一年多的工作经验，有两次工作经历，
	第一次是在亚新科技为期3个月的Linux运维实习,主要负责持续集成，以及测试环境的服务部署与维护
	第二次是在差旅一号，职位是Linux运维工程师,主要工作有线下机房的维护，线上环境的部署维护，日常问题处理
	
	今天我来贵公司应聘的职位是linux运维工程师，以上是我的自我介绍，谢谢。	


# 系统运维
### 1.编译安装configure、make、make install每个过程主要发生了些什么？ 

	./configure：检查系统环境是否符合满足安装要求，并将定义好的安装配置和系统环境信息写入Makefile文件中。里面包含了如何编译、启用哪些功能、安装路径等信息。
	
	make：make命令会根据Makefile文件进行编译。编译工作主要是调用编译器(如gcc)将源码编译为可执行文件，通常需要一些函数库才能产生一个完整的可执行文件。
	
	make install：将上一步所编译的数据安装到指定的目录下。

### 2.Linux内存管理中什么是RSS和VSZ？

	RSS 是常驻内存集（Resident Set Size），表示该进程分配的内存大小。
	RSS 不包括进入交换分区的内存。
	RSS 包括共享库占用的内存（只要共享库在内存中）
	RSS 包括所有分配的栈内存和堆内存。
	
	VSZ 表示进程分配的虚拟内存。
	VSZ 包括进程可以访问的所有内存，包括进入交换分区的内容，以及共享库占用的内存。
	
	如果一个进程，程序的大小有 500K，链接的共享库大小有 2500K，堆栈内存共有 200K，其中 100K 进入了交换分区。
	进程实际加载了共享库中的 1000K 的内容，以及自己程序的中的 400K 的内容。请问 RSS 和 VSZ 应是多少？
	
	RSS: 400K + 1000K + 100K = 1500K
	VSZ: 500K + 2500K + 200K = 3200K

### 3./etc/sysctl.conf 这个文件的意义？列举一些常见的kernel参数和作用？

	/etc/sysctl.conf这个目录主要是配置一些系统信息,而且它的内容全部是对应于/proc/sys/这个目录的子目录及文件。
	（1）shmmax：该参数定义了共享内存段的最大尺寸（以字节为单位）。缺省为32M，对于oracle来说，该缺省值太低了，通常将其设置为2G。
	（2）shmmni：这个内核参数用于设置系统范围内共享内存段的最大数量。该参数的默认值是 4096 。通常不需要更改。     
	（3）shmall：该参数表示系统一次可以使用的共享内存总量（以页为单位）。缺省值就是2097152，通常不需要修改。     
	（4）sem：该参数表示设置的信号量。     
	（5）file-max：该参数表示文件句柄的最大数量。文件句柄设置表示在linux系统中可以打开的文件数量。
	（6）ip_forward：开启内核转发
	
	vi /etc/sysctl.conf  这里修改参数
	sysctl -p  刷新后可用
	
	可直接echo重定向 /proc/sys/...，但只能临时生效

### 4.Linux系统是由那些部分组成？

	Linux系统内核，shell，文件系统和应用程序四部分组成。

### 5.一台Linux服务器负载高，连接慢，怎么查看？

	先用w看负载多少，用top看哪个进程占用cpu高，同时用top按M看哪个进程占用内存多，用iotop看哪个进程读写频繁，用sar命令或者nload命令查看网卡流量，是否跑满带宽.

### 6.Linux服务器中程序经常自动停止如何处理？

	临时解决：可以先写监控脚本，当发现进程不存在时自动启动。 
	最终解决：然后要查各个日志，看看程序为什么会自动停止，只有找到根本原因，才能真正解决问题.

### 7.NAS,SAN,DAS存储解析?

	NAS：网络附加储存 (Network Attached Storage)，是一种专业的资料储存技术的名称，它可以直接连接在电脑网络上面，对不同操作系统的使用者提供了集中式资料存取服务，代表有NFS，Samba
	SAN：存储区域网络（Storage Area Network），SAN存储通过光纤交换机将磁盘空间分配给不同的服务器，服务器通过以太网对外提供服务，存储区域与用户的应用区域隔离。
	DAS：直接附加存储(Direct Attached Storage)是指将存储设备通过SCSI接口或光纤通道直接连接到一台计算机上。
	
	总结：根据DAS、NAS、SAN的不同特性，DAS及SAN是基于存储空间的磁盘分配，是基于硬件层面的存储方式，而NAS则是基于应用层面的存储方式，可以根据应用环境来对其进行总结。
	
	DAS多采用SCSI或SAS接口，由于部署节点的单一性及较高的性能，适用于单一节点的企业级应用，或者地理位置比较分散的服务器使用。DAS由于部署的局限性目前使用量越来越少。
	
	NAS利用现有以太网网络，因此部署灵活，部署的成本非常低，基于TCP/IP协议的特性可以提供丰富的网络服务，基于文件的形式提供数据的存储及备份，
	但是TCP/IP协议决定了数据传输的数据打包及解包会占用系统资源，另外传输速率受限于以太网的速率，因此不适用于企业级应用，通常部署于部门级应用。
	
	SAN存储使用光纤网络进行传输，并且独立于应用网络，可以提供非常高的带宽，数据的传输基于块协议，无需对数据进行处理，直接进行传送，因此性能最好，
	另外光纤线路可以提供远距离的高带宽链路，可以实现数据中心的异地灾备应用，但是部署成本较高。因此SAN存储多应用于企业级的存储部署中。

### 8.linux环境变量设置?

	临时有效：
		~]# export NAME=NEW_NAME
	永久生效:
		1.在/etc/profile文件后追加
			NAME=NEWNAME
		  	~]# . /etc/profile
		2.在/etc/profile.d/目录下，生成一个.sh结尾的文件
			NAME=NEW_NAME
			~]# . /etc/profile

### 9.简述一下raid0，raid1、raid5、raid10他们的优势与区别?

	RAID，可以把硬盘整合成一个大磁盘，还可以在大磁盘上再分区，放数据
	还有一个大功能，多块盘放在一起可以有冗余（备份）
	
	RAID整合方式有很多，常用的：0 1 5 10
	
	RAID 0，可以是一块盘和N个盘组合 
	其优点读写快，是RAID中最好的
	缺点：没有冗余，一块坏了数据就全没有了
	
	RAID 1，至少2块盘，盘的大小可以不一样，以小的为准
	10G+10G只有10G，另一个做备份。它有100%的冗余
	缺点：浪费资源，成本高
	
	RAID 5，至少3块盘，容量计算 SIZE（最小的盘容量）*（n-1）,损失一块盘
	特点，读写性能一般，读还好一点，写不好
	
	冗余从好到坏：RAID1 RAID10 RAID5 RAID0
	性能从好到坏：RAID0 RAID10 RAID5 RAID1
	成本从低到高：RAID0 RAID5 RAID1 RAID10
	
	单台服务器：很重要盘不多，系统盘，RAID1
	数据库服务器：主库：RAID10 
				 从库 RAID5\RAID0（为了维护成本，RAID10）
	WEB服务器，如果没有太多的数据的话，RAID5,RAID0（单盘）
			  有多台，监控、应用服务器，RAID0 RAID5
	
	我们会根据数据的存储和访问的需求，去匹配对应的RAID级别

### 10.常见的Linux版本有哪些？你最擅长哪一种？说明你擅长哪一块？

	常见的Linux发行版有，Debian, Gentoo, Ubuntu, RedHat, CentOS, Fedora,  Kali Linux, Suse等.
	最擅长CentOS，擅长部分命令使用，脚本编程，环境服务搭建与配置。

### 11.什么是linux的daemon进程？和一般进程有什么区别？

	守护进程的第一个特征是长时间在后台运行的程序，并且主要是为了提供某种服务，而为了能够让服务尽可能随时都可用，就要求这个服务是一直运行的，
	于是守护进程就守护着这个服务不挂掉。linux里面常见的守护进程一般都是以d结尾的，比如apache的httpd,samba的smbd,ssh的sshd。

### 12.解释/etc/fstab文件中每个字段的意义?

	<file system> <mount point> <type> <options> <dump> <pass>
	
	<file system>：要挂载的文件系统的设备名称或块信息，也可以是远程的文件系统  
	<mount point>：挂载点
	<type>：文件系统类型
	<options>：挂载选项，类型较多，默认为default，通过 man mount 来查看
	<dump>：此处为1的话，表示要将整个<fie sysytem>里的内容备份；为0的话，表示不备份。现在很少用到dump这个工具，在这里一般选0。
	<pass>：这里用来指定如何使用fsck来检查硬盘。如果这里填0，则不检查；挂载点为 / 的（即根分区），必须在这里填写1，其他的都不能填写1。
			如果有分区填写大于1的话，则在检查完根分区后，接着按填写的数字从小到大依次检查下去。
			同数字 的同时检查。比如第一和第二个分区填写2，第三和第四个分区填写3，则系统在检查完根分区后，接着同时检查第一和第二个分区，然后再同时检查第三和第四个分区。

### 13.软连接与硬连接的区别?

	在Linux的文件系统中，保存在磁盘分区中的文件不管是什么类型都给它分配一个编号，称为索引节点号inode 。
	
	软连接，其实就是新建立一个文件，这个文件就是专门用来指向别的文件的（那就和windows 下的快捷方式的那个文件有很接近的意味）。
	软链接产生的是一个新的文件，但这个文件的作用就是专门指向某个文件的，删了这个软连接文件，那就等于不需要这个连接，和原来的存在的实体原文件没有任何关系，
	但删除原来的文件，则相应的软连接不可用（cat那个软链接文件，则提示“没有该文件或目录“）
	
	硬连接是不会建立inode的，他只是在文件原来的inode link count域再增加1而已，也因此硬链接是不可以跨越文件系统的。
	相反是软连接会重新建立一个inode，当然inode的结构跟其他的不一样，他只是一个指明源文件的字符串信息。一旦删除源文件，
	那么软连接将变得毫无意义。而硬链接删除的时候，系统调用会检查inode link count的数值，如果他大于等于1，那么inode不会被回收。因此文件的内容不会被删除。
	
	硬链接实际上是为文件建一个别名，链接文件和原文件实际上是同一个文件。可以通过ls -i来查看一下，这两个文件的inode号是同一个，说明它们是同一个文件；
	而软链接建立的是一个指向，即链接文件内的内容是指向原文件的指针，它们是两个文件。
	
	异同：
		1.软链接可以跨文件系统，硬链接不可以；
		2.软链接可以对一个不存在的文件名(filename)进行链接（当然此时如果你vi这个软链接文件，linux会自动新建一个文件名为filename的文件）,硬链接不可以（其文件必须存在，inode必须存在）；
		3.软链接可以对目录进行连接，硬链接不可以。
	
	两种链接都可以通过命令 ln 来创建。ln 默认创建的是硬链接。使用 -s 开关可以创建软链接。

### 14.http协议中的keeplive是做什么的？它的适应场景是什么？

	(1)Http(超文本传输协议)底层也是通过TCP传输的。
	
	(2)HTTP keep-alive
	   Http是一个”请求-响应”协议，它的keep-alive主要是为了让多个http请求共享一个Tcp连接，以避免每个Http又新建一个TCP连接。每个Http服务器默认的keep-alive时间可能是不一样的。
	
	(3)直接介绍一个场景就可能更容易明白了。客户端发送了一个Http请求，服务器响应后，判断这个Http是否是keep-alive模式的，如果不是则关闭连接,如果是keep-alive，
	则等待keep-alive time后再关闭，如果这期间再收到一个http 请求，则继续等待最后一个请求的keep-alive time时间，直到keep-alive time时间内没有收到请求，则关闭。
	
	(4)上面是HTTP keep-alive的，而TCP是它下一层的协议，本身TCP是长连接的，除非主动关闭。HTTP的keep-alive time一般是15ms, 30ms之类的，
	如果是超过了HTTP的keep-alive time时间，则HTTP会关闭TCP连接。本身TCP是不会关闭连接的，HTTP的keep alive是TCP的保鲜装置，
	在keep alive timeout 后服务端发送一个监测包来判断连接是否仍保持着，如果还是可连接，则继续保持，它不会主动关闭连接的。而心跳包是为了防止NAT超时。

### 15.进程与线程?

	(1)进程是资源分配的最小单位，线程是程序执行的最小单位。
	
	(2)进程有自己的独立地址空间，每启动一个进程，系统就会为它分配地址空间，建立数据表来维护代码段、堆栈段和数据段，这种操作非常昂贵。
	而线程是共享进程中的数据的，使用相同的地址空间，因此CPU切换一个线程的花费远比进程要小很多，同时创建一个线程的开销也比进程要小很多。
	
	(3)线程之间的通信更方便，同一进程下的线程共享全局变量、静态变量等数据，而进程之间的通信需要以通信的方式（IPC)进行。
	不过如何处理好同步与互斥是编写多线程程序的难点。
	
	(4)但是多进程程序更健壮，多线程程序只要有一个线程死掉，整个进程也死掉了，而一个进程死掉并不会对另外一个进程造成影响，因为进程有自己独立的地址空间。

### 16.如何发现linux系统是否出现性能瓶颈？请例举出你常用的监控命令以及参数?

	A. 用w命令看系统负载高不高，如果高可能是CPU不够用，进程太多运行太慢，也可能是磁盘I/O太高了。
	B. 用vmstat 1命令来查看各个指标，着重分析r,b,swpd,si,so,bi,bo,us,wa. 若r列或者us列数值偏高则说明cpu有瓶颈，若b列或者wa列数值偏高同时bi或bo的数字很大，则说明磁盘有压力，若swpd一直变化，并且si和so一直不为0，则说明内存不够了。
	C. 用top命令来分析哪个进程耗费cpu最多，默认按使用cpu多少排序，按M也可以按内存使用多少排序。
	D. 用sar -n DEV 1 10 或者 nload 命令可以查看网卡的流量（若没有nload命令，请使用yum install epel-release; yum install -y nload 安装）
	E. 用iotop命令可以查看磁盘读写速度 （yum install -y iotop 安装）

### 17.防火墙的四表五链？

	netfilter/iptables(下文简称为iptables)组成Linux平台下的包过滤防火墙, 与大多数的Linux软件一样, 这个包过滤防火墙是免费的, 
	它可以代替昂贵的商业防火墙解决方案, 完成封包过滤, 封包重定向和网络地址转换NAT等功能.
	
	当主机收到一个数据包后，数据包先在内核空间中处理，若发现目的地址是自身，则传到用户空间中交给对应的应用程序处理，若发现目的不是自身，则会将包丢弃或进行转发。
	
	虽然 netfilter/iptables IP 信息包过滤系统被称为单个实体, 但它实际上由两个组件 netfilter 和 iptables 组成.
	
	netfilter 组件也称为内核空间(kernelspace)组件, 是内核的一部分, 由一些信息包过滤表组成, 这些表包含内核用来控制信息包过滤处理的规则集.
	iptables 组件是一种工具, 也称为用户空间(userspace), 它使插入, 修改和除去信息包过滤表中的规则变得容易.
	
	4个表为:
	
	filter: 一般的过滤功能.
	nat: 用于nat功能(端口映射, 地址映射等).
	mangle: 用于对特定数据包的修改.
	raw: 优先级最高, 设置raw时一般是为了不再让iptables做数据包的链接跟踪处理, 提高性能.
	默认表是filter(没有指定表的时候就是filter表). 表的处理优先级: raw > mangle > nat > filter.
	
	5个链为: PREROUTING, INPUT, FORWARD, OUTPUT, POSTROUTING.
	
	PREROUTING: 数据包进入路由表之前.
	INPUT: 通过路由表后目的地为本机.
	FORWARDING: 通过路由表后, 目的地不为本机.
	OUTPUT: 由本机产生, 向外转发.
	POSTROUTIONG: 发送到网卡接口之前.

### 18.Linux的运行级别 

	0.关机
	1.单用户
	2.无网络多用户
	3.命令行
	4.未用
	5.图形
	6.重启
	
	查看：who -r | runlevel
	切换：init num

### 19.centos 6.X版本系统 和 centos 7.X版本有啥区别？

	1.文件系统（6/ext4、7/xfs）
	2.内核版本（6/2.6x、7/3.10x）
	3.防火墙（6/iptables、7/firewalld）
	4.默认数据库（6/mysql、7/mariadb）
	5.启动服务（6/service启动、7/systemctl启动）
	6.网卡（6/eth0、7/ens192）等。

### 20.如何开启linux服务器路由转发功能？

	echo "1" > /proc/sys/net/ipv4/ip_forward

### 21.网站登陆缓慢是什么原因?

	1.网络带宽，这是一个很常见的瓶颈。
	2.cpu、硬盘、内存配置过低，服务器负载不起来。
	3.网站的开发代码不够完善，例如mysql语句没有进行优化，导致数据库的读写相当耗费时间。
	4.数据库的瓶颈。当我们的数据库的数据变得越来越多的时候，那么对于数据库的读写压力肯定会变大。

### 22.如果PING不通怎么排查?

	1.首先先看看是不是网路接口故障或是网卡接口接触不良造成，其次检查交换机和路由等网络设备是有故障
	2.是否关闭了防火墙和selinux机制
	3.然后查看网卡和路由和网关是否配置正确
	4.查看是否因为网络异常

### 23.什么是僵尸进程与孤儿进程?

	孤儿进程：一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集工作。
	
	僵尸进程：一个进程使用fork创建子进程，如果子进程退出，而父进程并没有调用wait或waitpid获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中。这种进程称之为僵尸进程。

### 24.LINUX系统软件安装和卸载的常见方法？

	1.rpm包卸载：rpm -e XXX.rpm(如果想忽略依赖，可加上–nodeps)
	
	2.yum remove xxx.rpm  这种方法非常不建议使用，卸载过程会将待卸载的软件包所依赖的软件包一并卸载掉，很容易造成系统缺少某些包而崩溃等问题
	
	3.源码包卸载：cd命令进入编译后的软件目录，即安装时的目录，执行make uninstall命令即可；或者直接删除安装目录

### 25.umask 022代表什么意思？

	掩码：用于限制创建文件权限
	普通文件：666-umask
	目录：777-umask

### 26.如何通过端口查找进程？如何查看某进程所打开的所有文件？如何动态的修改文件数？如何查看程序的所有进程信息？

	lsof -i:PORT		#可得到进程号
	
	lsof -p PID			#可查看进程打开的所有文件
	
	在 /proc/PID 目录下修改
	
	pstree -p PID		#使用pstree命令可查看程序所有进程信息

### 27.常用的网络管理工具（5种以上）

	Linux下有：ifconfig,ip,ping,traceroute,dig,nslookup,iftop,nload...

### 28.对运维的了解，为什么选择运维

	运维是指大型组织已经建立好的网络软硬件的维护，就是要保证业务的上线与运作的正常，在它运转的过程中，对他进行维护，它集合了网络、系统、数据库、开发、安全、监控于一身的技术。
	运维又包括很多种，有DBA运维、网站运维、虚拟化运维、监控运维、游戏运维等等。
	
	运维工程师在公司当中责任重大，需要保证时刻为公司及客户提供最高、最快、最稳定、最安全的服务
	运维工程师的一个小小的失误，很有可能会对公司及客户造成重大损失，因此运维工程师的工作需要严谨及富有创新精神

### 29.现在给你三百台服务器，你怎么对他们进行管理？

	管理3百台服务器的方式：
	1）设定跳板机，使用统一账号登录，便于安全与登录的考量。
	2）使用salt、ansiable、puppet进行系统的统一调度与配置的统一管理。
	3）建立简单的服务器的系统、配置、应用的cmdb信息管理。便于查阅每台服务器上的各种信息记录。 
	4) 监控系统的添加与监控

### 30.如何优化 Linux系统（可以不说太具体）？

	1.不用root，添加普通用户，通过sudo授权管理
	2.更改默认的远程连接SSH服务端口及禁止root用户远程连接
	3.定时自动更新服务器时间
	4.配置国内yum源
	5.关闭selinux及iptables（iptables工作场景如果有外网IP一定要打开，高并发除外）
	6.调整文件描述符的数量
	7.精简开机启动服务（crond rsyslog network sshd）
	8.内核参数优化（/etc/sysctl.conf）
	9.更改字符集，支持中文，但建议还是用英文字符集，防止乱码
	10.锁定关键系统文件
	11.清空/etc/issue，去除系统及内核版本登录前的屏幕显示

### 31.用什么命令可以查看上一次服务器启动的时间、上一次谁登录过服务器？

	w命令查看上次服务器启动时间，并可以查看当前几个用户在线
	
	last命令用于显示用户最近登录信息。单独执行last命令，它会读取/var/log/wtmp的文件，并把该给文件的内容记录的登入系统的用户名单全部显示出来。

### 32.热备份、冷备份、温备份的区别

	按照是否能够继续提供服务，将数据库备份类型划分为：
	
	热备份：在线备份，能读能写
	温备份：能读不能写
	冷备份：离线备份
	
	按照备份数据库对象分类：
	物理备份：直接复制数据文件
	逻辑备份：将数据导出至文件中，必要时将其还原(也包括备份成sql语句的方式)
	
	按照是否备份整个数据集分为：
	完全备份：备份从开始到某段时间的全部数据
	差异备份：备份自完全备份以来变化的数据
	增量备份：备份自上次增量备份以来变化的数据


### 33.使用swap内存有什么好处，在什么情况下swap内存才会被使用？你觉得在生产环境中要不要用swap内存？

	好处：在内存不够用的时候，将部分内存上的数据交换到swap空间上，以便让系统不会因为内存不够用而导致oom或者更致命的情况出现。
	
	什么情况下会用swap：当系统的物理内存不够用的时候，就需要将物理内存中的一部分空间释放出来，以供当前运行的程序使用。
	那些被释放的空间可能来自一些很长时间没有什么操作的程序，这些被释放的空间被临时保存到swap空间中，等到那些程序要运行时，
	再从swap中恢复保存的数据到内存中。这样，系统总是在物理内存不够时，才进行swap交换。
	
	swap大小约为物理内存的两倍

### 34.在linux服务器上,不管是用rz -y命令还是tftp工具上传，本地的一个文件上传到服务器完成后，服务器上什么都没有，这可能是什么问题？

	根据这种现象有可能是：服务器磁盘满了；文件格式破坏了；或者你用的是普通用户上传，正好上传的目录没有权限；还有可能就是你上传的文件大小超出了该目录空间的范围。

### 35.死锁、原因、解决、避免

	死锁是指两个或两个以上的进程在执行过程中，由于竞争资源或者由于彼此通信而造成的一种阻塞的现象，若无外力作用，它们都将无法推进下去。
	此时称系统处于死锁状态或系统产生了死锁，这些永远在互相等待的进程称为死锁进程。
	
	原因：
		互斥：资源不能共享，只能由一个进程持有 
		占有且等待：当一个等待另外进程而阻塞时，资源不主动释放 
		不可抢占：操作系统不能强行抢占被进程持有的资源 
		循环等待：存在一个封闭的进程链，使得每一个进程都至少占有下个进程所需要的资源。
	
	预防：
		破坏第一个是不可能的，资源本来就是互斥的；
		第二个占有且等待，可以要求进程一次性地请求所有需要的资源，并且阻塞到所有请求同时满足；
		不可抢占，将进程持有的资源抢占，也是于理不合。
	
	避免：
		1. 进程启动拒绝。如果在进程启动时，看看系统已经分配的和剩余的资源能不能满足进程需要的最大资源，如果不能，直接拒绝 
		2. 资源分配拒绝。采用银行家算法，当进程请求一组资源时，假设同意该请求，从而改变系统的状态，然后确定其结果是能够使系统处于安全状态。
		如果是，则同意该请求，如果不是，阻塞该进程直到同意该请求后系统状态能够处于安全状态。
	
	恢复： 
		1. 取消所有的死锁进程 
		2. 连续取消死锁进程，直到不再死锁。

### 36.rsync+inotify是实现文件实时同步的，加什么参数才能实现实时同步，--delete参数又是什么意思？

	rsync是远程同步工具、inotify是一种强大的异步文件系统系统监控机制。通过inotifywait中的-m参数可以实现"始终保持事件监听状态"。
	rsync中的-delete参数是指"删除那些DST中SRC没有的文件"。

### 37.如何发布和回滚，用jenkins又是怎么实现？

	发布：jenkins配置好代码路径（SVN或GIT），然后拉代码，打tag。需要编译就编译，编译之后推送到发布服务器（jenkins里面可以调脚本），然后从分发服务器往下分发到业务服务器上。
	
	回滚：按照版本号到发布服务器找到对应的版本推送

### 38.SUID、SGID、SBIT权限?

	SUID：s位，二进制可执行程序，任何用户执行该程序都拥有属主的权限
	SGID：g位
		1.二进制可执行程序，任何用户执行该程序都拥有属组的权限
		2.对于文件夹，在该文件夹下创建的文件和目录，都将和该文件夹权限一致
	SBIT：t位，粘滞位，对于目录，该目录下创建的文件只有属主和管理员能进行删除操作

### 39.ext4文件系统原理(未答)

### 40.不用工具恢复ext4删除文件(未答)

### 41.系统启动流程详细说明(未答)

### 42.高并发的架构设计(未答)

### 43.linux内核分为哪四个子系统

	进程管理、内存管理、IO管理系统、文件系统管理
	网络接口


### 44.简述centos7系统systemd管理工具，以及centos6系统service的主要区别？(未答)

### 45.ss命令为什么比netstat命令快

	netstat命令是去遍历/proc目录下的PID文件来实现统计
	
	而ss快的秘诀在于它利用到了TCP协议栈中tcp_diag。tcp_diag是一个用于分析统计的模块，可以获得Linux内核中第一手的信息，这就确保了ss的快捷高效。
	当然，如果你的系统中没有tcp_diag，ss也可以正常运行，只是效率会变得稍慢（但仍然比 netstat要快）。

### 46.linux的fork了解吗？什么是写时复制机制？

	Linux的fork()使用写时拷贝(copy-on-write)页实现。写时拷贝是一种可以推迟甚至避免拷贝数据的技术。
	内核此时并不复制整个进程的地址空间，而是让父子进程共享同一个地址空间。只用在需要写入的时候才会复制地址空间，从而使各个进行拥有各自的地址空间。
	也就是说，资源的复制是在需要写入的时候才会进行，在此之前，只有以只读方式共享。这种技术使地址空间上的页的拷贝被推迟到实际发生写入的时候。

### 47.du和df的区别

	1.两者区别 
	du：disk usage,是通过搜索文件来计算每个文件的大小然后累加，du能看到的文件只是一些当前存在的，
		没有被删除的。他计算的大小就是当前他认为存在的所有文件大小的累加和。
	df：disk free，通过文件系统来快速获取空间大小的信息，当我们删除一个文件的时候，这个文件不是马上就在文件系统当中消失了，而是暂时消失了，
		当所有程序都不用时，才会根据OS的规则释放掉已经删除的文件， df记录的是通过文件系统获取到的文件的大小，他比du强的地方就是能够看到已经删除的文件，
		而且计算大小的时候，把这一部分的空间也加上了，更精确了。当文件系统也确定删除了该文件后，这时候du与df就一致了。
	
	2.du查看目录大小，df查看磁盘使用情况。

### 48.提高性能和并发数，需要优化哪些内核参数

	net.ipv4.tcp_max_tw_buckets = 6000  			//timewait的数量，默认是180000。
	net.ipv4.ip_local_port_range = 1024 65000  	//允许系统打开的端口范围。
	net.ipv4.tcp_tw_reuse = 1 					//允许将TIME-WAIT sockets 重新用于新的TCP 连接。
	net.ipv4.tcp_syncookies = 1 				//开启SYN Cookies，当出现SYN 等待队列溢出时，启用cookies 来处理。
	net.ipv4.tcp_max_orphans = 262144 			//系统中最多有多少个TCP套接字不被关联到任何一个用户文件句柄上。如果超过这个数字，孤儿连接将即刻被复位并打印出警告信息。
												  这个限制仅仅是为了防止简单的DoS攻击，不能过分依靠它或者人为地减小这个值，更应该增加这个值(如果增加了内存之后)。
	net.ipv4.tcp_max_syn_backlog = 262144  	//记录的那些尚未收到客户端确认信息的连接请求的最大值。对于有128M内存的系统而言，缺省值是1024，小内存的系统则是128。
	net.ipv4.tcp_synack_retries = 1  		//为了打开对端的连接，内核需要发送一个SYN 并附带一个回应前面一个SYN的ACK。也就是所谓三次握手中的第二次握手。这个设置决定了内核放弃连接之前发送SYN+ACK 包的数量。
	net.ipv4.tcp_syn_retries = 1  			//在内核放弃建立连接之前发送SYN 包的数量。
	net.ipv4.tcp_keepalive_time = 30 		//当keepalive 起用的时候，TCP 发送keepalive 消息的频度。缺省是2 小时。

### 49.简单介绍一下您所知道的加速web服务器的请求的方法。

	A. 针对静态的访问，做过期时间，把静态文件缓存在客户端上
	
	B. 在前端搭建squid反向代理，把静态的文件缓存在squid上
	
	C. 接入CDN
	
	D. 合并js、css以及小图片


### 50.常用Linux命令

	cd/cp/ls/rm/mv/cat
	查看负载：top/upload
	内存：free
	磁盘使用状况：df
	文本编辑器：vim
	网卡信息：ifconfig，ss
	脚本常用：awk/sed/grep/cut/uniq/sort/wc

### 51.centos开机过程中,服务(/etc/init.d中的)因故障卡住，不能开机，怎么办？

	卡住之后重启电脑（可按ctrl+alt+delete,如果这个被禁用了则想其他方法），然后进入开机启动画面按esc按键
	进入之后按a,然后输入1，单用户启动。（利用单用户启动基本上不会启动任何守护进程的特性来跳过卡住的服务的启动过程）
	利用chkconfig --list 服务名 命令来查看卡住的服务的错误原因并修复。如果短时间内无法修复，则先利用chkconfig 服务名 off 命令先关掉此服务开机启动，然后正常启动计算机
	正常启动后再慢慢寻找原因修复服务，先保证计算机能启动并且提供其他的正常业务进行。


### 52.蓝绿部署、金丝雀/灰度部署、滚动发布

	蓝绿部署：蓝绿部署指的是不停老版本代码(不影响上一个版本访问)，而是在另外一套环境部署新版本然后进行测试，测试通过后将用户流量切到新版本，其特点为业务无中断，升级风险相对较小。
	
	金丝雀发布/灰度发布：金丝雀发布也叫灰度发布，是指在黑与白之间，能够平滑过渡的一种发布方式，灰度发布是增量发布的一种类型，灰度发布是在原有版本可用的情况下，
					  同时部署一个新版本应用作为"金丝雀"(小白鼠)，测试新版本的性能和表现，以保障整体系统稳定的情况下，尽早发现、调整问题。
	
	滚动发布：滚动发布，一般是取出一个或者多个服务器停止服务，执行更新，并重新将其投入使用。周而复始，直到集群中所有的实例都更新成新版本

### 53.磁盘IOPS与吞吐量如何理解？

```c
IOPS (Input/Output Per Second)即每秒的输入输出量(或读写次数)，是衡量磁盘性能的主要指标之一。IOPS是指单位时间内系统能处理的I/O请求数量，I/O请求通常为读或写数据操作请求。随机读写频繁的应用，如OLTP(Online Transaction Processing)，IOPS是关键衡量指标。另一个重要指标是数据吞吐量(Throughput)，指单位时间内可以成功传输的数据数量。对于大量顺序读写的应用，如VOD(Video On Demand)，则更关注吞吐量指标。简而言之：

磁盘的 IOPS，也就是在一秒内，磁盘进行多少次 I/O 读写。
磁盘的吞吐量，也就是每秒磁盘 I/O 的流量，即磁盘写入加上读出的数据的大小。

IOPS 与吞吐量的关系:
	每秒 I/O 吞吐量＝ IOPS* 平均 I/O SIZE
从公式可以看出： I/O SIZE 越大，IOPS 越高，那么每秒 I/O 的吞吐量就越高。因此，我们会认为 IOPS 和吞吐量的数值越高越好。实际上，对于一个磁盘来讲，这两个参数均有其最大值，而且这两个参数也存在着一定的关系。
        
传统磁盘本质上一种机械装置，如FC, SAS, SATA磁盘，转速通常为5400/7200/10K/15K rpm不等。影响磁盘的关键因素是磁盘服务时间，即磁盘完成一个I/O请求所花费的时间，它由寻道时间、旋转延迟和数据传输时间三部分构成。
        
寻道时间Tseek：是指将读写磁头移动至正确的磁道上所需要的时间。寻道时间越短，I/O操作越快，目前磁盘的平均寻道时间一般在3－15ms。
旋转延迟Trotation：是指盘片旋转将请求数据所在扇区移至读写磁头下方所需要的时间。旋转延迟取决于磁盘转速，通常使用磁盘旋转一周所需时间的1/2表示。比如，7200 rpm的磁盘平均旋转延迟大约为60*1000/7200/2 = 4.17ms，而转速为15000 rpm的磁盘其平均旋转延迟约为2ms。
数据传输时间Transfer：是指完成传输所请求的数据所需要的时间，它取决于数据传输率，其值等于数据大小除以数据传输率。目前IDE/ATA能达到133MB/s，SATA II可达到300MB/s的接口数据传输率，数据传输时间通常远小于前两部分时间。

因此，理论上可以计算出磁盘的最大IOPS，即IOPS = 1000 ms/ (Tseek + Troatation)，忽略数据传输时间。假设磁盘平均物理寻道时间为3ms, 磁盘转速为7200,10K,15K rpm，则磁盘IOPS理论最大值分别为，
 IOPS = 1000 / (3 + 60000/7200/2)  = 140
 IOPS = 1000 / (3 + 60000/10000/2) = 167
 IOPS = 1000 / (3 + 60000/15000/2) = 200

固态硬盘SSD是一种电子装置， 避免了传统磁盘在寻道和旋转上的时间花费，存储单元寻址开销大大降低，因此IOPS可以非常高，能够达到数万甚至数十万。实际测量中，IOPS数值会受到很多因素的影响，包括I/O负载特征(读写比例，顺序和随机，工作线程数，队列深度，数据记录大小)、系统配置、操作系统、磁盘驱动等等。因此对比测量磁盘IOPS时，必须在同样的测试基准下进行，即便如何也会产生一定的随机不确定性。通常情况下，IOPS可细分为如下几个指标：
	Toatal IOPS，混合读写和顺序随机I/O负载情况下的磁盘IOPS，这个与实际I/O情况最为相符，大多数应用关注此指标。
	Random Read IOPS，100%随机读负载情况下的IOPS。
	Random Write IOPS，100%随机写负载情况下的IOPS。
	Sequential Read IOPS，100%顺序负载读情况下的IOPS。
	Sequential Write IOPS，100%顺序写负载情况下的IOPS。

IOPS的测试benchmark工具主要有Iometer, IoZone, FIO等，可以综合用于测试磁盘在不同情形下的IOPS。
        
参考文章：https://blog.csdn.net/liuaigui/article/details/6168186
https://blog.csdn.net/hanchengxi/article/details/19089589?utm_medium=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase
https://blog.csdn.net/star890124/article/details/52004138
        
```

### 54.Centos查看某个进程的环境变量？
```c
通过ps拿到进程PID

~]# cat /proc/PID/environ	#可查看环境变量
 
```


# 网络运维

### 1.什么是arp协议？什么是arp欺骗？

	ARP协议，全称“Address Resolution Protocol”,中文名是地址解析协议，使用ARP协议可实现通过IP地址获得对应主机的物理地址（MAC地址）。
	ARP协议要求通信的主机双方必须在同一个物理网段（即局域网环境）！
	局域网内，通过广播发现主机，广播自己的IP与mac并发出目标IP，具有目标IP的设备会响应并回复mac，其他机器会判断是否更新arp表

### 2.traceroute原理？

	IP：IP协议是TCP/IP协议族中最核心的部分，它的作用是在两台主机之间传输数据，所有上层协议的数据（HTTP、TCP、UDP等）都会被封装在一个个的IP数据包中被发送到网络上。
	
	ICMP：ICMP全称为互联网控制报文协议，它常用于传递错误信息，ICMP协议是IP层的一部分，它的报文也是通过IP数据包来传输的。
	
	TTL：TTL（time-to-live）是IP数据包中的一个字段，它指定了数据包最多能经过几次路由器。从我们源主机发出去的数据包在到达目的主机的路上要经过许多个路由器的转发，在发送数据包的时候源主机会设置一个TTL的值，每经过一个路由器TTL就会被减去一，当TTL为0的时候该数据包会被直接丢弃（不再继续转发），并发送一个超时ICMP报文给源主机。
	
	traceroute命令用来发现IP接力路径(route)上的各个路由器。它向目的地发送IP包，第一次的时候，将TTL设置为1，引发第一个路由器的超时（Time Exceeded）错误。
	这样，第一个路由器回复ICMP包，从而让出发主机知道途径的第一个路由器的信息。随后TTL被设置为2、3、4，...，直到到达目的主机。
	这样，沿途的每个路由器都会向出发主机发送ICMP包来汇报错误。traceroute将ICMP包的信息打印在屏幕上，就是接力路径的信息了。

### 3.OSI七层模型及简单说明？

	物理层： 主要定义物理设备标准，如网线的接口类型、各种传输介质的传输速率等。主要作用是传输比特流
		   （就是由1、0转化为电流强弱来进行传输，到达目的地后再转化为1、0，也就是常说的数模与模数转换）。这一层的数据叫做比特（bit），主要设备：集线器。
	数据链路层： 主要将从物理层接收的数据进行MAC地址的封装与解封装。常把这层的数据叫做帧，主要设备：网卡，交换机。协议：ARP、RARP
	网络层： 选择合适的网间路由和交换节点，确保数据及时传送，将从下层接收到数据进行 IP 地址的封装与解封装。通常把这一层数据叫做数据包，主要设备：路由器。协议：IP、ICMP、IGMP
	传输层： 定义了一些传输数据的协议和端口，如TCP、UDP协议，主要将从下层接收的数据进行分段和传输，到达目的地址后再进行重组，以往把这一层数据叫做段。协议：TCP、UDP
	会话层： 通过传输层建立数据传输通路。在系统之间发起会话或者接受会话请求（设备之间需要相互认识）。
	表示层： 主要是进行对接收的数据进行解释、压缩与解压缩等，即把计算机能够识别的东西转化为人能够识别的东西（如图片、声音等）。
	应用层： 主要是一些终端的应用，比如说FTP（各种文件下载）、浏览器、QQ，以及域名系统DNS（将域名解析为IP，及其反解）等，
			可以将其理解为在电脑屏幕上可以看到的东西，也就是终端应用。协议：HTTP、DNS、FTP、SMTP...

### 4.TCP报头格式

	源端口（16位）、目的端口（16位）
	序列号（32位）：传输数据过程中，为每一个封包分配一个序号，保证网络传输数据的顺序性
	确认号（32位）：用来确认确实有收到相关封包，内容表示期望收到下一个报文的序列号，用来解决丢包的问题
	头部长度（4位）：标识该TCP头部有多少个32bit(4字节)。因为4位最大能表示15，所以TCP头部最长是60字节；保留位（6位）；标志位（6位）；滑动窗口（16位）
	校验码（16位）、紧急指针（16位）

### 5.tcp和udp的区别，tcp的特点

	可以答，tcp面向连接，可靠。udp具有实时性，高效高速传输。tcp是点到点通信，udp支持多对多，简单
	
	TCP/IP 协议是一个协议簇,里面包括 TCP IP 以及 UDP等很多个协议,由于TCP, IP两个比较重要,所以用他们两个命名.
	
	TCP/IP网络模型分为四层: 应用层, 传输层, 网络层, 网络接入层
	应用层包括: 超文本传输协议(HTTP),文本传输协议(FTP),远程登录(Telnet)等
	传输层包括:为应用提供端到端的通信功能,保证了数据包的传输顺序及数据完整性.两个主要协议就是 TCP 和 UDP
	网络层:解决主机到主机的通信问题.该层有三个主要协议:网际协议(IP),互联网组管理协议(IGMP),和互联网控制报文协议(ICMP)
	网络接入层:负责监视数据在主机和网络之间的交换
	
	TCP 和 UDP 的区别: 
	TCP:Transmission Control Protocol ,传输控制协议,TCP 是面向连接,可靠的,基于字节流的传输层通信协议. 
	UDP:User Datagram Protocol,即用户数据报协议,是面向非连接的协议,它不与对方建立连接,而是直接把数据包发送过去.
	
	二者特点:
	TCP 特点: 使用流模式,保证数据传输顺序,面向连接,可靠,速度慢,不可以发送广播.发送需要通过3次”握手”建立连接,连接可靠.
	3次握手过程: 
	1) 第一次握手: 客户端将syn包(即同步包)(同步序列编号Synchronize Sequence Number)发送给服务器,服务器进入SYN_SEND状态 
	2) 第二次握手: 服务器收到并确认客户端的syn包,然后也发送一个SYN包(SYN+ACK包),此时服务器进入 YN_RECV状态 
	3) 第三次握手: 客户端收到服务器的 SYN+ACK包后,向服务器发送确认包ACK,发送完毕,客户端和服务器进入 ESTABLISHED(TCP连接成功)状态,完成三次握手.
	
	(1)面向连接：采用C/S模型
	(2)全双工
	(3)安全可靠：
		①流量控制：解决接收方不能不及时处理数据的问题
		②拥塞控制：解决因网络通信延迟带来的数据丢失问题
		③差错控制：解决数据被破坏、重复、时序和丢失的问题
	(4)基于字节流
	
	UDP 特点: 使用数据报格式,面向报文,无连接,对系统的资源要求少,不可靠,速度快,容易丢包,UDP不保证数据传输顺序,可以发送广播

### 6.简述三次握手？为什么需要三次握手？

	三次握手：
		1.建立连接时，客户端发送SYN包请求连接，此时SYN标志位为1，且会生成随机序列号seq=a，客户端进入SYN_SEND状态
		2.服务端接收到客户端请求连接包后，需回复ACK应答包，并发送SYN包请求连接，合并为ACK+SYN包，
	 	  此时服务器也会生成随机序列号seq=b,ack序列号置为a+1,表示下个想要收到的包的序列号为a+1，服务端进入SYN_RECV状态 
		3.客户端收到服务端的应答包后，回复一个ACK应答包，此时ACK置为1，seq=a+1,ack=b+1,表示客户端想要收到下个包的序列号为b+1，
		  客户端进入ESTABLISHED状态，服务端收到ACK应道包后就进入ESTABLISHED状态
	
	为什么要三次握手：
		当第二次握手时，服务端的包延迟了，超过了客户端超时时长，由于tcp时可靠连接，客户端会重新发送第一次握手包，
		但最后服务端第一次发送的延迟包还是到达了，此时就会生成两个连接，浪费资源，
		如果加了第三次客户端确认，客户端在接受到一个服务端连接确认请求后，后面再接收到的连接确认请求就可以抛弃不管了。

### 7.简述四次分手？为什么需要四次分手？

	四次分手：
		1.客户端主动断开连接，发送FIN包，此时FIN标志位置为1，seq=x，x为从建立连接到传输了多少包后得到的序列号，客户端进入FIN_WAIT_1状态
		  此时客户端讲不能再给服务端发送数据
		2.服务端接收到客户端的断开请求后，发送ACK应答包，此时ACK标志位置为1，ack=x+1，seq=y，y为建立连接后到发送多少包后得到的序列号，服务端进入CLOSE_WAIT状态，此时服务端会将未发送完成的数据继续发送给客户端，客户端收到服务端的包后进入FIN_WAIT_2状态
		3.传输完成后，服务端会发送一个FIN包，此时FIN标志位置为1，ack=x+1，seq=w，w未第二次分手发送包后得到的序列号，服务端进入LAST_ACK状态
		  此时双方都不能在传输数据
		4.客户端收到第三次分手的包后，会发送ACK应答包，表示已经收到，此时ACK标志位置为1，ack=w+1，seq=x+1，客户端进入TIME_WAIT状态
		  但是此时TCP连接还没有释放，然后经过等待计时器设置的2MSL后，才进入到CLOSED状态。
	
	为什么需要四次分手才能安全断开连接？
	  	因为TCP连接是全双工的,即双方都要停止连接才能安全断开。当第一次分手时，客户端变为FIN_WAIT1状态，此时客户端将不能再给服务器发送数据，
		但仍可接收来自服务器的数据。当服务器将给客户端的数据发送完毕后，服务器确认断开，双方都不能在发送数据。客户端将进入time_wait状态。
	
	为什么客户端要等待2MSL后才进入CLOSED状态？
	  	首先，MSL即Maximum Segment Lifetime，就是最大报文生存时间，是任何报文在网络上的存在的最长时间，超过这个时间报文将被丢弃。
		《TCP/IP详解》中是这样描述的：MSL是任何报文段被丢弃前在网络内的最长时间。RFC 793中规定MSL为2分钟，
		实际应用中常用的是30秒、1分钟、2分钟等( /proc/sys/net/ipv4/tcp_fin_timeout参数)。
	
	  	TCP的TIME_WAIT需要等待2MSL，当TCP的一端发起主动关闭，三次挥手完成后发送第四次挥手的ACK包后就进入这个状态，
		等待2MSL时间主要目的是：防止最后一个ACK包对方没有收到，那么对方在超时后将重发第三次挥手的FIN包，主动关闭端接到重发的FIN包后可以再发一个ACK应答包。
		在TIME_WAIT状态时两端的端口不能使用，要等到2MSL时间结束才可以继续使用。当连接处于2MSL等待阶段时任何迟到的报文段都将被丢弃。


### 8.TCP的可靠连接是怎么实现的？

	数据超时重传：发送发从发送数据开始计时，
	数据确认应答：接收方收到后会发送一个ack应答包
	每个传输的数据包分配序列号

### 9.能解释一下TCP的超时重传机制吗?

	重新发送TCP片段的机制：超时重新发送和快速重新发送。 
	
	超时重传：当发送方送出一个TCP片段后，将开始计时，等待该TCP片段的ACK回复。如果接收方正确接收到符合次序的片段，接收方会利用ACK片段回复发送方。
			 发送方得到ACK回复后，继续移动窗口，发送接下来的TCP片段。如果直到计时完成，发送方还是没有收到ACK回复，那么发送方推断之前发送的TCP片段丢失，
			 因此重新发送之前的TCP片段。这个计时等待的时间叫做重新发送超时时间(RTO, retransmission timeout)。
			 RTO时长取决于数据片段（发送方到接收方，接收方ack到发送方）往返时间(RTT, round trip time)。
	
	快速重传：TCP协议规定，当接收方收到乱序片段的时候，需要重复发送ACK。比如接收到乱序片段9的时候，接收方需要回复ACK。回复号为8 (7+1)。
			 此后接收方如果继续收到乱序片段(序号不是8的片段)，将再次重复发送ACK=8。当发送方收到3个ACK=8的回复时，发送方推断片段8丢失。
			 即使此时片段8的计时器还没有超时，发送方会打断计时，直接重新发送片段8，这就是快速重新发送机制(fast-retransmission)。
			 快速重新发送机制利用重复的ACK来提示空洞的存在。当重复次数达到阈值时，认为空洞对应的片段在网络中丢失。快速重新发送机制提高了检测丢失片段的效率，
			 往往可以在超时之前探测到丢失片段，并重复发送丢失的片段。

### 10.TCP/IP的流量控制?

	通过滑动窗口控制流量
	
	发送发滑动窗口分为：发送但没收到ack回复，等待发送
	接收方滑动窗口分为：收到数据且已发送ack但没给进程读取，收到数据但没发送ack，没有收到数据
	
	当接收方进程过于忙碌，不能及时取走滑窗中的数据，接收方滑窗就会变小，并在TCP头部的window size大小进行调整，接收方会同步划窗大小，从而实现流量控制。
	它告诉对方本端的TCP接收缓冲区还能容纳多少字节的数据，这样对方就可以控制发送数据的速度。

### 11.TCP拥塞控制及方法?

	在TCP协议中，我们使用连接记录TCP两端的状态，使用编号和分段实现了TCP传输的有序，使用advertised window来实现了发送方和接收方处理能力的匹配，并使用重复发送来实现TCP传输的可靠性。
	
	TCP除了通过控制滑窗(sliding window)大小来控制发送速率，以实现TCP流量控制。TCP还会维护一个congestion window size，以根据网络状况来调整滑窗大小。
	真实滑窗大小取这两个滑窗限制的最小值，从而同时满足两个限制 (流量控制和堵塞控制)。
	
	congestion window总是处于两种状态的一个。这两种状态是: 慢起动(slow start)和堵塞避免(congestion avoidance)。
	
	Congestion window从slow start的状态开始。Slow start的特点是初始速率低，但速率不断倍增。每次进入到slow start状态时，cwnd都需要重置为初始值1。
	发送方每接收到一个正确的ACK，就会将congestion window增加1，从而实现速率的倍增(由于累计ACK，速率增长可能会小于倍增)。
	
	当congestion window的大小达到某个阈值ssthresh时，congestion进入到congestion avoidance状态。发送速率会继续增长。发送方在每个窗户所有片段成功传输后，
	将窗口尺寸增加1(实际上就是每个RTT增加1)。所以在congestion avoidance下，cwnd线性增长，增长速率慢。
	
	如果在congestion avoidance下有片段丢失，重新回到slow start状态，并将ssthresh更新为cwnd的一半。


### 12.如何处理time_wait状态

	编辑内核文件/etc/sysctl.conf，加入以下内容：
	
	net.ipv4.tcp_syncookies = 1 表示开启SYN Cookies。当出现SYN等待队列溢出时，启用cookies来处理，可防范少量SYN攻击，默认为0，表示关闭；
	net.ipv4.tcp_tw_reuse = 1 表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭；
	net.ipv4.tcp_tw_recycle = 1 表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭。
	net.ipv4.tcp_fin_timeout 修改系默认的 TIMEOUT 时间
	然后执行 /sbin/sysctl -p 让参数生效.
	
	/etc/sysctl.conf是一个允许改变正在运行中的Linux系统的接口，它包含一些TCP/IP堆栈和虚拟内存系统的高级选项，修改内核参数永久生效。
	简单来说，就是打开系统的TIMEWAIT重用和快速回收。
	
	如果以上配置调优后性能还不理想，可继续修改一下配置：


	~]# vi /etc/sysctl.conf
	net.ipv4.tcp_keepalive_time = 1200 
	#表示当keepalive起用的时候，TCP发送keepalive消息的频度。缺省是2小时，改为20分钟。
	
	net.ipv4.ip_local_port_range = 1024 65000 
	#表示用于向外连接的端口范围。缺省情况下很小：32768到61000，改为1024到65000。
	
	net.ipv4.tcp_max_syn_backlog = 8192 
	#表示SYN队列的长度，默认为1024，加大队列长度为8192，可以容纳更多等待连接的网络连接数。
	
	net.ipv4.tcp_max_tw_buckets = 5000 
	#表示系统同时保持TIME_WAIT套接字的最大数量，如果超过这个数字，TIME_WAIT套接字将立刻被清除并打印警告信息。
	默认为180000，改为5000。对于Apache、Nginx等服务器，上几行的参数可以很好地减少TIME_WAIT套接字数量，但是对于 Squid，效果却不大。
	此项参数可以控制TIME_WAIT套接字的最大数量，避免Squid服务器被大量的TIME_WAIT套接字拖死。


### 13.WAN、LAN、VPN

	局域网(Local Area Network，LAN)：是指在某一区域内由多台计算机互联成的计算机组。一般是方圆几千米以内。
	局域网可以实现文件管理、应用软件共享、打印机共享、工作组内的日程安排、电子邮件和传真通信服务等功能。
	局域网是封闭型的，可以由办公室内的两台计算机组成，也可以由一个公司内的上千台计算机组成。
	
	广域网 (Wide Area Network，WAN):是一种跨越大的、地域性的计算机网络的集合。通常跨越省、市，甚至一个国家。
	广域网包括大大小小不同的子网，子网可以是局域网，也可以是小型的广域网。
	
	虚拟专用网络(Virtual Private Network，VPN):虚拟专用网络功能是：在公用网络上建立专用网络，进行加密通讯。
	在企业网络中有广泛应用。VPN 网关通过对数据包的加密和数据包目标地址的转换实现远程访问。


### 14.路由器和交换机的区别？

	1.路由器工作在三层，交换机工作在二层
	2.路由器通过ip寻址，交换机通过mac寻址
	3.路由器提供防火墙功能，交换机没有此功能

### 15.什么是socket？

	网络套接字，当两台主机建立起TCP连接时，就会在两台主机上分别生成一个Socket文件，并由内核进行维护
	完整的套接字格式：
	  protocol ： TCP/UDP
	  src_addr： 源IP
	  src_port ： 源port
	  dest_addr： 目的IP
	  dest_port ： 目的port


​	
### 16.五种IO模型？简述基于tcp协议的套接字通信流程？

	出于安全考虑，系统不允许应用空间直接调用硬件，需要发起系统调用，通过内核去调用
	同步阻塞IO：应用app发起read()系统调用-->内核将数据从磁盘读取到内核buffer-->内核buffer拷贝到应用app buffer-->app buffer 到tcp/ip协议栈-->NIC
			   前三步app会被阻塞，直到数据拷贝到app buffer或出错才会被唤醒
	
	同步非阻塞IO：应用app发起read()系统调用，内核立即返回一个错误值EWOULDBLOCK，应用app不断发read()调用，直到内核准备好-->
				内核将数据从磁盘读取到内核buffer-->内核buffer拷贝到应用app buffer-->app buffer 到tcp/ip协议栈-->NIC
				第三步会被阻塞，数据拷贝到app buffer或出错才会被唤醒		
	
	IO复用模型：应用app发起系统调用select/poll/epoll，所有套接字注册到select/poll/epoll，进程被阻塞-->
				内核会监视所有select负责的的socket，当socket的数据准备好后，就立即返回-->
				进程再调用read操作，数据就会从内核buffer拷贝到app buffer。--> app buffer 到tcp/ip协议栈-->NIC
				第三步会被阻塞，数据拷贝到app buffer或出错才会被唤醒	


​				
​	信号驱动IO模型：当开启了信号驱动功能时，首先发起一个信号处理的系统调用，如sigaction()，这个系统调用会立即返回-->
​				  但数据在准备好时，会发送SIGIO信号，进程收到这个信号就知道数据准备好了，发起read操作-->
​				  进程再调用read操作，数据就会从内核buffer拷贝到app buffer。--> app buffer 到tcp/ip协议栈-->NIC
​				  在发起信号处理的系统调用后，进程不会被阻塞，但是在read()将数据从kernel buffer复制到app buffer时，进程是被阻塞的。
​	
	异步IO模型：应用app发起aio_read()-->内核将数据从磁盘读取到内核buffer-->内核buffer拷贝到应用app buffer-->app buffer 到tcp/ip协议栈-->NIC
	 			全程不被阻塞


### 17.mmap与sendfile技术？

	数据完成传输过程：
	客户端请求-->服务器内核空间-->服务器用户空间app-->app发起系统调用如read-->内核访问磁盘获取数据并拷贝到内核buffer-->内核buffer拷贝到app buffer-->app buffer拷贝到TCP/IP协议栈socket buffer-->socket buffer数据从NIC出去
	
	mmap技术：减少一次到用户空间的拷贝
	客户端请求-->服务器内核空间-->服务器用户空间app-->app发起系统调用如read-->内核访问磁盘获取数据并拷贝到内核buffer,并作出内存映射，app可直接访问内存数据-->app buffer拷贝到TCP/IP协议栈socket buffer-->socket buffer数据从NIC出去
	
	sendfile技术：准备的数据直接不经过用户空间
	客户端请求-->服务器内核空间-->服务器用户空间app-->app发起系统调用如read-->内核访问磁盘获取数据并拷贝到内核buffer-->内核 buffer直接拷贝到TCP/IP协议栈socket buffer-->socket buffer数据从NIC出去


### 18.什么是粘包？socket 中造成粘包的原因是什么？ 粘包的处理方式

	粘包：在接收数据时,一次性多接收了其它请求发送来的数据（即多包接收）。
	如，对方第一次发送hello，第二次发送world，在接收时，应该收两次，一次是hello，一次是world，但事实上是一次收到helloworld，一次收到空，这种现象叫粘包。
	 
	原因：粘包问题主要还是因为接收方不知道消息之间的界限，不知道一次性提取多少字节的数据所造成的。
	 	
	什么情况会发生：
	1.发送端需要等缓冲区满才发送出去，造成粘包（发送数据时间间隔很短，数据很小，会合到一起，产生粘包）
	2.接收方不及时接收缓冲区的包，造成多个包接收（客户端发送了一段数据，服务端只收了一小部分，服务端下次再收的时候还是从缓冲区拿上次遗留的数据，产生粘包）
	 
	解决方案：
 	一个思路是发送之前，先打个招呼，告诉对方自己要发送的字节长度，这样对方可以根据长度判断什么时候终止接受。

### 19.请解释cookie和session的实现原理和区别

	session原理：Session 是存放在服务器端的，类似于Session结构来存放用户数据，当浏览器 第一次发送请求时，
	服务器自动生成了一个Session和一个Session ID用来唯一标识这个Session，并将其通过响应发送到浏览器。
	当浏览器第二次发送请求，会将前一次服务器响应中的Session ID放在请求中一并发送到服务器上，服务器从请求中提取出Session ID，
	并和保存的所有Session ID进行对比，找到这个用户对应的Session。
	
	cookie原理：如果浏览器使用的是 cookie，那么所有的数据都保存在浏览器端，比如你登录以后，服务器设置了 cookie用户名(username),
	那么，当你再次请求服务器的时候，浏览器会将username一块发送给服务器，这些变量有一定的特殊标记。服 务器会解释为 cookie变量。
	cookie当不设置有效时间，关闭浏览器cookie就失效，设置有效时间会保存在磁盘中，下次登录仍然有效。
	
	区别：
		1.cookie数据存放在客户的浏览器上，session数据放在服务器上。
		2.cookie不是很安全，别人可以分析存放在本地的COOKIE并进行COOKIE欺骗考虑到安全应当使用session。
		3.session会在一定时间内保存在服务器上。当访问增多，会比较占用你服务器的性能考虑到减轻服务器性能方面，应当使用COOKIE。

### 20.http、https、ftp、smtp、pop3、 ssh、dns、snmp、mysql、sql分别用的什么端口。

	http:	80(tcp)
	https:	443(tcp)
	ftp:	21(tcp)
	smtp:	25(tcp)
	pop3:	110(tcp)
	ssh:	22(tcp)
	dns:	53(tcp/udp)
	snmp:	()
	mysql:	3306
	sql:	3389
	telent:	23
	DHCP:	67
	tomcat:	8080
	redis:	6379
	oracle:	1521/1526
	mongdb:	27017
	...

### 21.说一下http状态码吧?

	1**：临时响应
	2**：成功请求
	3**：重定向
	4**：客户端错误
	5**：服务端错误 
	
	200：请求被成功接收
	304：请求的内容没有被修改过
	403：客户端错误，没有权限，拒绝访问
	404：客户端错误，访问的网页不存在
	500：服务器内部错误，服务器未能实现合法的请求
	503：服务器当前不能处理客户端的请求，过一段时间再试
	
	502: Bad Gateway。主要是因为后端服务器,比如uswgi响应的内容是nginx无法理解的，那么就可能出现502。比如在后端服务器挂掉的情况下就会出现502
	504: Gateway timeout. 主要是因为后端服务器处理任务太久，超过nginx的等待阈值。比如将nginx的请求等待时间设置得太小就可能出现504
	503: Service unavailable.主要是因为瞬间并发量太大，导致后端服务器没有足够的资源去处理请求

### 22.进程间通信方式

	同一主机：
		管道（FIFO、PIPE）
		共享内存
		消息队列
		信号量
	网络：
		socket（网络套接字）

### 23.说说保留的IP字段是哪些,IP地址的分类

	IP(Internet protocol)地址：网络号+主机号
	
	IPv4:32bits
		8bits:8bits:8bits:8bits
			0-255
			0.0.0.0-255.255.255.255
	
		IP地址分类
			A类：
				第一段为网络号，后三段为主机号
				网络号：
					0 000 0000 - 0 111 1111 ：1-127
				网络数量：2^7 （126, 127为本地回环接口）
				每个网络中的主机数量：2^24-2,	0.0.0,	255.255.255
				默认	子网掩码：255.0.0.0
					用于与IP地址按位进行"与"运算，从而取出其网络地址
					1.3.2.1/255.0.0.0=1.0.0.0
					1.3.2.1/255.255.0.0=1.3.0.0	
				私网地址：10.0.0.0/255.0.0.0
			
			B类：
				前两段为网络号，后两段为主机号
				网络号：
					10 00 0000 - 10 11 1111 ：128-191
				网络数：2^14
				每个网络中的主机数量：2^16-2
				默认子网掩码：255.255.0.0
				私网地址：172.16.0.0-172.31.0.0
		
			C类：
				前三段为网络号，最后一段为主机号
				网络号：
					110 0 0000 - 110 1 1111 ：192-223
				网络数：2^21
				每个网络中的主机号：2^8-2
				默认子网掩码：255.255.255.0,24(24个1)
			
			D类：组播
				1110 0000 - 1110 1111:224-239
			
			E类：科研
				240-255

### 24.http协议你所知道的所有方法?

	1	GET	请求指定的页面信息，并返回实体主体。
	2	HEAD	类似于get请求，只不过返回的响应中没有具体的内容，用于获取报头
	3	POST	向指定资源提交数据进行处理请求（例如提交表单或者上传文件）。数据被包含在请求体中。POST请求可能会导致新的资源的建立和/或已有资源的修改。
	4	PUT	从客户端向服务器传送的数据取代指定的文档的内容。
	5	DELETE	请求服务器删除指定的页面。
	6	CONNECT	HTTP/1.1协议中预留给能够将连接改为管道方式的代理服务器。
	7	OPTIONS	允许客户端查看服务器的性能。
	8	TRACE	回显服务器收到的请求，主要用于测试或诊断。

### 25.HTTP协议(头结构，几种请求方法，缓存机制，各版本的区别)?

	HTTP协议全称HyperText Transfer Protocol，中文名超文本传输协议。是互联网上应用最为广泛的一种网络协议。
	HTTP是基于TCP/IP协议的应用层协议，不涉及数据包的传输，主要是规定了客户端和服务器之间的通信格式。默认使用80端口。现在HTTP已经演化出了很多个版本。

### 26.谈谈你对Https协议的理解？对称加密与非对称加密?CA的作用？工作方式？

	HTTPS 是由 HTTP 协议+SSL 协议构成。SSL 协议通过对信息进行加密，为网络通信提供安全保障。
	
	对称加密   ：加密解密使用同一密钥，加解密速度快。AES/DES/3DES
	非对称加密 ：使用公私钥配对加解密，速度慢。公钥是从私钥中提取出来的，一般拿对方公钥加密来保证数据安全性，拿自己的私钥加密来证明数据来源的身份。RSA/DSA			
	单向加密   ：不算是加密，也常称为散列运算，用于生成独一无二的校验码(或称为指纹、特征码)来保证数据的完整性和一致性，如MD5、SHA。
			    具有雪崩效应，任何一点数据的改变，生成的校验码值变化非常大。
	
	CA：证书颁发机构，用户将一些个人信息发送给CA进行颁发证书
	
	CA机构持有的公钥

# 数据库运维

### 1.MySQL的MyISAM与InnoDB引擎有什么区别？

	1.InnoDB支持事物，而MyISAM不支持事物
	
	2.InnoDB支持行级锁，而MyISAM支持表级锁
	
	3.InnoDB支持MVCC（多版本并发控制，MVCC 是一种并发控制的方法）, 而MyISAM不支持
	
	4.InnoDB支持外键，而MyISAM不支持
	
	5.InnoDB不支持全文索引，而MyISAM支持。

### 2.什么是MySQL事务？事务有几种隔离级别？

	事务（transaction）是作为一个单元的一组有序的数据库操作。如果组中的所有操作都成功，则认为事务成功，即使只有一个操作失败，事务也不成功。
	如果所有操作完成，事务则提交，其修改将作用于所有其他数据库进程。如果一个操作失败，则事务将回滚，该事务所有操作的影响都将取消
	
	事务具有ACID特性：原子性(A,atomicity)、一致性(C,consistency)、隔离性(I,isolation)、持久性(D,durabulity)。
	
	原子性：事务内的所有操作要么都执行，要么都不执行。
	一致性：事务开始和结束前后，数据都满足数据一致性约束，而不是经过事务控制之后数据变得不满足条件或业务规则。
	隔离性：事务之间不能互影响，它们必须完全的各行其道，互不可见。
	持久性：事务完成后，该事务内涉及的数据必须持久性的写入磁盘保证其持久性。当然，这是从事务的角度来考虑的的持久性，从操作系统故障或硬件故障来说，这是不一定的。
	
	事务的四种隔离级别：
		1.read uncommitted：未提交读，即允许读取未提交的数据，脏读
		2.read committed：提交读，当事务提交后才能读取。不可重复读
		3.repeatable read：可重复读，总是会在事务开启的时候读取最新提交的行版本，并将该行版本一直持有到事务结束。幻影读。
		4.serializable：串行，每一个事务必须等待前一个事务(哪怕是只有查询的事务)结束后才能进行哪怕只是查询的操作。比较严格。
	
		READ-UNCOMMITTED：读未提交 --> 脏读
		READ-COMMITTED	：读提交   --> 不可重复读,一个事务内
		REPEATABLE-READ	：可重复读 --> 幻读，一个事务内
		SERIALIZABLE	：串行化

### 3.什么是mysql索引？有什么用处？

	什么是索引：索引(Index)是帮助MySQL高效获取数据的数据结构。我们可以简单理解为：快速查找排好序的一种数据结构。
	
	Mysql索引主要有两种结构：B+Tree索引和Hash索引。我们平常所说的索引，如果没有特别指明，一般都是指B树结构组织的索引(B+Tree索引)。
	
	a)、索引的目的是什么？
		1.快速访问数据表中的特定信息，提高检索速度
		2.创建唯一性索引，保证数据库表中每一行数据的唯一性。
		3.加速表和表之间的连接
		4.使用分组和排序子句进行数据检索时，可以显著减少查询中分组和排序的时间
	
	b)、索引对数据库系统的负面影响是什么？
		1.创建索引和维护索引需要耗费时间，这个时间随着数据量的增加而增加；
		2.索引需要占用物理空间，不光是表需要占用数据空间，每个索引也需要占用物理空间；当对表进行增、删、改、的时候索引也要动态维护，这样就降低了数据的维护速度。
	
	c)、为数据表建立索引的原则有哪些？
		1.在最频繁使用的、用以缩小查询范围的字段上建立索引。
		2.在频繁使用的、需要排序的字段上建立索引
	
	d)、 什么情况下不宜建立索引？
		1.对于查询中很少涉及的列或者重复值比较多的列，不宜建立索引。
		2.于一些特殊的数据类型，不宜建立索引，比如文本字段（text）等


### 4.MySQL数据备份工具？

	(a)mysqldump：逻辑备份工具。要求mysql服务在线。MyISAM(温备)，InnoDB（热备），逻辑备份
	(b)mysqlhotcopy：物理备份工具，温备份，实际上是冷备。加锁、flush table并进行cp或scp。即将废弃的工具
	(c)cp/tar：冷备
	(d)lvm快照：几乎热备。注意点是：先flush table、lock table、创建快照、释放锁、复制数据。\
			   因为要先flush table和lock table，这对于MyISAM来说很简单很容易实现。但对于InnoDB来说，\
			   因为事务的原因，锁表后可能还有缓存中的数据在写入文件中，所以应该监控缓存中的数据是真的已经完全写入数据文件中，之后才能进行复制数据。
	(e)xtrabackup：开源。MyISAM（温备），InnoDB（热备），速度较快。物理备份
				   完全备份、部分备份
				   完全备份、增量备份
				   完全备份、差异备份

### 5.如何设计一个高并发的系统？

	1. 数据库的优化，包括合理的事务隔离级别、SQL语句优化、索引的优化
	2. 使用缓存，尽量减少数据库 IO
	3. 分布式数据库、分布式缓存
	4. 服务器的负载均衡

### 6.什么情况下设置了索引但无法使用？

	1.以"%"开头的LIKE语句，模糊匹配
	2.OR语句前后没有同时使用索引
	3.数据类型出现隐式转化（如varchar不加单引号的话可能会自动转换为int型）
	4.没有使用最左原则的组合索引。
	5.如果mysql估计使用全表扫描要比使用索引快,则不使用索引

### 7.实践中如何优化MySQL

	我当时是按以下四条依次回答的，他们四条从效果上第一条影响最大，后面越来越小。
	1.SQL语句及索引的优化
	2.数据库表结构的优化
	3.系统配置的优化
	4.硬件的优化

### 8.简单描述MySQL中，索引，主键索引，唯一索引，联合索引的区别，对数据库的性能有什么影响（从读写两方面）?

	索引是一种特殊的文件(InnoDB数据表上的索引是表空间的一个组成部分)，它们包含着对数据表里所有记录的引用指针。
	
	普通索引(由关键字KEY或INDEX定义的索引)的唯一任务是加快对数据的访问速度。普通索引允许被索引的数据列包含重复的值。
	
	如果能确定某个数据列将只包含彼此各不相同的值，在为这个数据列创建索引的时候就应该用关键字UNIQUE把它定义为一个唯一索引。也就是说，唯一索引可以保证数据记录的唯一性。
	
	主键索引，是一种特殊的唯一索引，在一张表中只能定义一个主键索引，主键用于唯一标识一条记录，使用关键字PRIMARY KEY 来创建。
	
	索引可以覆盖多个数据列，如像INDEX(columnA, columnB)索引，这就是联合索引。遵循最左原则。
	
	索引可以极大的提高数据的查询速度，但是会降低插入、删除、更新表的速度，因为在执行这些写操作时，还要操作索引文件。

### 9.什么是联合索引的最左原则？

	联合索引中，比如(name,age,sex)的时候，b+数是按照从左到右的顺序来建立搜索树的，比如当(张三,20,F)这样的数据来检索的时候，
	b+树会优先比较name来确定下一步的所搜方向，如果name相同再依次比较age和sex，最后得到检索的数据；但当(20,F)这样的没有name的数据来的时候，
	b+树就不知道下一步该查哪个节点，因为建立搜索树的时候name就是第一个比较因子，必须要先根据name来搜索才能知道下一步去哪里查询。
	比如当(张三,F)这样的数据来检索时，b+树可以用name来指定搜索方向，但下一个字段age的缺失，所以只能把名字等于张三的数据都找到，
	然后再匹配性别是F的数据了， 这个是非常重要的性质，即索引的最左匹配特性。

### 10.写出三种以上MySQL数据库存储引擎的名称（提示：不区分大小写）？

	MyISAM、InnoDB、BDB（BerkeleyDB）、Merge、Memory（Heap）、Example、Federated、Archive、CSV、Blackhole、MaxDB 等等十几个引擎

### 11.SQL语言包括哪几部分？每部分都有哪些操作关键字？

	答：SQL语言包括数据定义(DDL)、数据操纵(DML),数据控制(DCL)
	
	数据定义：Create Table,Alter Table,Drop Table, Craete/Drop Index等
	
	数据操纵：Select ,insert,update,delete
	
	数据控制：grant,revoke

### 12.什么是锁？

	数据库是一个多用户使用的共享资源。当多个用户并发地存取数据时，在数据库中就会产生多个事务同时存取同一数据的情况。
	若对并发操作不加控制就可能会读取和存储不正确的数据，破坏数据库的一致性。
	
	加锁是实现数据库并发控制的一个非常重要的技术。当事务在对某个数据对象进行操作前，先向系统发出请求，对其加锁。加锁后事务就对该数据对象有了一定的控制，
	在该事务释放锁之前，其他的事务不能对此数据对象进行更新操作。
	
	锁类型：
	读锁：共享锁，可被多个读操作共享
	写锁：排它锁，独占锁
	
	锁粒度：
	表锁：在表级别施加锁，并发性较低
	行锁：在行级别施加锁，并发性较高，维持锁状态的成本较大

### 13.MySQL日志类型与基本作用？

	1.错误日志：	
		（1）mysqld启动和关闭过程输出的信息
		（2）mysqld运行中产生的错误信息
		（3）event scheduler运行时产生的信息
		（4）主从复制架构中，从服务器复制线程启动时产生的日志
	
	2.查询日志
		在超时时间内完成的查询操作记录到此日志，一般不推荐打开
	
	3.慢查询日志
		查询超出变量 long_query_time 指定时间值的为慢查询。但是查询获取锁(包括锁等待)的时间不计入查询时间内。
	
	4.二进制日志
		二进制日志包含了引起或可能引起数据库改变(如delete语句但没有匹配行)的事件信息，但绝不会包括select和show这样的查询语句。
		语句以"事件"的形式保存，所以包含了时间、事件开始和结束位置等信息。
	
		二进制日志是以事件形式记录的，不是事务日志(但可能是基于事务来记录二进制日志)，不代表它只记录innodb日志，myisam表也一样有二进制日志。
	
		二进制日志只在事务提交的时候一次性写入(基于事务的innodb二进制日志)。	
	
	5.中继日志
		主从复制时使用的日志
	
	6.事务日志


### 14.二进制日志的记录格式？

	日志的记录格式由变量 binlog_format 来指定。其值有：row,statement,mixed
	
	Statement：每一条会修改数据的sql都会记录在binlog中，记录sql语句
	row：不记录sql语句上下文相关信息，仅保存哪条记录被修改。如一条update语句，修改多条记录，则binlog中每一条修改都会有记录，这样造成binlog日志量会很大
	mixed：混合模式，一般的语句修改使用statment格式保存binlog，如一些函数，statement无法完成主从复制的操作，则采用row格式保存binlog


### 15.MySQL的主从复制原理以及流程，并简述配置过程？

	主数据库需要启动二进制日志，bin-log,id参数
	1. 主：记录下所有改变了数据库数据的语句，放进master上的binlog中；
	2. 从：io线程在使用start slave 之后，会监控master上的binlog，并负责从master上拉取 binlog 内容，放进 自己的relay log中；
	3. 从：sql执行线程执行relay log中的语句；
	
	主：
	    1.开启master bin-log
	        log-bin=mysql-log
	        server-id=1  #这个必须不同
	
	    2.授权从库账号    
	        mysql> grant replication slave on *.* to 'rep'@'192.168.179.%' identified by '960711';
	        mysql> flush privileges;
	
	    3.若主库已有数据，需要先将主库数据备份到从库    
	        mysql> flush table with read lock;  #只允许读数据，不允许写数据。
	            注:锁表后数据库不能退出，备份可在新窗口进行
	        mysql> show master status;    #查看bin-log文件和位置，用于从库同步起始位置
	        ~]# mysqldump -uroot -p --all-databases --master-data=2 > dump_all.db
	            注:加上--master-data=2参数，可直接获取bin-log文件及位置，加-x参数，备份时自动锁表 
	        mysql> unlock tables; #解锁
	
	从：
	    1.开启中继日志
	        relay_log=slave_log
	        server-id=3
	
	        注：relay_log.info用于记录SQL线程信息
	    2.设置连接    
	        mysql> CHANGE MASTER TO
	               MASTER_HOST='192.168.179.110',
	               MASTER_PORT=3306,
	               MASTER_USER='rep',
	               MASTER_PASSWORD='960711',
	               MASTER_LOG_FILE='mysql-bin.000003',
	               MASTER_LOG_POS=1452;
	        #该信息会存放在master.info，用于记录IO线程信息中
	
	    3.打开slave开关    
	        start slave
	
	    4.查看slave状态    
	        show slave status\G;
	        #若出现如下为成功:   
	            Slave_IO_Running: Yes
	            Slave_SQL_Running: Yes

### 16.问innodb的事务与日志的实现方式？

	事务日志是通过redo和innodb的存储引擎日志缓冲（Innodb log buffer）来实现的，当开始一个事务的时候，会记录该事务的lsn(log sequence number)号; 
	当事务执行时，会往InnoDB存储引擎的日志的日志缓存里面插入事务日志；当事务提交时，必须将存储引擎的日志缓冲写入磁盘（通过innodb_flush_log_at_trx_commit来控制），
	也就是写数据前，需要先写日志。这种方式称为“预写日志方式”



### 17.新安装MYSQL后怎样提升MYSQL的安全级别

	1.修改mysql默认端口
	2.linux下可以通过iptables来限制访问mysql端口的IP地址
	3.对所有用户设置较复杂密码并严格指定对应账号的访问IP（可在mysql库中user表中指定用户的访问可访问IP地址）
	4.root特权账号的处理（建议给root账号设置强密码，并指定只允许本地登录）
	5.开启二进制查询日志和慢查询日志
	6.mysql安装目录及数据存储目录权限控制：给mysql安装目录读取权限，给mysql日志和数据所在目录读取和写入权限
	7.删除无用mysql账号和删除无用的数据库（安装好的mysql默认会有个test库，可将其删除）

### 18.mysql复制模式（同步，异步，半同步，延迟）

	同步复制：客户端发送DDL/DML语句给master，master执行完毕后还需要等待所有的slave都写完了relay log才认为此次DDL/DML成功，然后才会返回成功信息给客户端。
			 同步复制的问题是master必须等待，所以延迟较大，在MySQL中不使用这种复制方式。
	
	半同步复制：客户端发送DDL/DML语句给master，master执行完毕后还要等待一个slave写完relay log并返回确认信息给master，master才认为此次DDL/DML语句是成功的，
			   然后才会发送成功信息给客户端。半同步复制只需等待一个slave的回应，且等待的超时时间可以设置，超时后会自动降级为异步复制，
			   所以在局域网内(网络延迟很小)使用半同步复制是可行的。
	
	异步复制：客户端发送DDL/DML语句给master，master执行完毕立即返回成功信息给客户端，而不管slave是否已经开始复制。这样的复制方式导致的问题是，
			 当master写完了binlog，而slave还没有开始复制或者复制还没完成时，slave上和master上的数据暂时不一致，且此时master突然宕机，slave将会丢失一部分数据。
			 如果此时把slave提升为新的master，那么整个数据库就永久丢失这部分数据。
	
	延迟复制：延迟复制就是故意让slave延迟一段时间再从master上进行复制。

### 19.GTID（global transaction id)复制原理

	1、master更新数据时，会在事务前产生GTID，一同记录到binlog日志中。
	2、slave端的i/o 线程将变更的binlog，写入到本地的relay log中。
	3、sql线程从relay log中获取GTID，然后对比slave端的binlog是否有记录。
	4、如果有记录，说明该GTID的事务已经执行，slave会忽略。
	5、如果没有记录，slave就会从relay log中执行该GTID的事务，并记录到binlog。
	6、在解析过程中会判断是否有主键，如果没有就用二级索引，如果没有就用全部扫描。

### 20.MySQL的innodb如何定位锁问题，MySQL如何减少主从复制延迟？

	mysql的innodb如何定位锁问题:
		在使用 show engine innodb status 检查引擎状态时，发现了死锁问题
		在5.5中，information_schema 库中增加了三个关于锁的表（MEMORY引擎）
		
		innodb_trx         ## 当前运行的所有事务
		
		innodb_locks     ## 当前出现的锁
		
		innodb_lock_waits  ## 锁等待的对应关系


	mysql如何减少主从复制延迟:
		如果延迟比较大，就先确认以下几个因素：
		1. 从库硬件比主库差，导致复制延迟
		2. 主从复制单线程，如果主库写并发太大，来不及传送到从库就会导致延迟。更高版本的mysql可以支持多线程复制
		3. 慢SQL语句过多
		4. 网络延迟
		5. master负载主库读写压力大，导致复制延迟，架构的前端要加buffer及缓存层
		6. slave负载一般的做法是，使用多台slave来分摊读请求，再从这些slave中取一台专用的服务器只作为备份用，不进行其他任何操作.另外， 2个可以减少延迟的参数:
		   #参数含义：当slave从主数据库读取log数据失败后，等待多久重新建立连接并获取数据	
		   –slave-net-timeout=seconds 单位为秒 默认设置为 3600秒
		   #参数含义：当重新建立主从连接时，如果连接建立失败，间隔多久后重试
		   –master-connect-retry=seconds 单位为秒 默认设置为 60秒
		
		   通常配置以上2个参数可以减少网络问题导致的主从数据同步延迟

### 21.MySQL数据库主从同步延迟解决方案

	最简单的减少slave同步延时的方案就是在架构上做优化，尽量让主库的DDL快速执行
	
	还有就是主库是写，对数据安全性较高，比如sync_binlog=1，innodb_flush_log_at_trx_commit=1 之类的设置，而slave则不需要这么高的数据安全，完全可以将sync_binlog设置为0或者关闭binlog
	innodb_flushlog也可以设置为0来提高sql的执行效率。另外就是使用比主库更好的硬件设备作为slave

# 应用运维

## Nginx
### 1.Nginx的应用场景？

	1、http服务器。Nginx是一个http服务可以独立提供http服务。可以做网页静态服务器。
	2、虚拟主机。可以实现在一台服务器虚拟出多个网站，例如个人网站使用的虚拟机。
	3、反向代理，负载均衡。当网站的访问量达到一定程度后，单台服务器不能满足用户的请求时，需要用多台服务器集群可以使用nginx做反向代理。
	并且多台服务器可以平均分担负载，不会应为某台服务器负载高宕机而某台服务器闲置的情况。

### 2.LVS、Nginx、HAproxy有什么区别？工作中你怎么选择？

	LVS是四层负载软件
	Nginx，HAproxy能够实现四层负载，也能实现七层负载
	
	Nginx和lvs负载均衡比较：
	
	1）nginx工作在网络的七层，所以他可以针对http应用本身来做分流策略，比如针对域名，目录等，而lvs并不具备这些功能，所以nginx这点可利用的地方就多于lvs
	2）nginx对网络的依赖性比较小，理论上只要能ping通，网页访问正常，nginx就能连的通，lvs比较依赖于网络环境，至少需要一个公网ip来做VIP
	3）nginx测试可以查看错误日志，而lvs出错，很多都是网络问题，没有错误日志，解决比较麻烦
	4）nginx可以检测到服务器内部的故障，比如根据服务器处理网页返回的状态码、超时等等，并且会把返回错误的请求重新提交到另一个节点。
	   lvs的原理使其不能重发请求。比如用户正在上传一个文件，而处理该上传的节点刚 好在上传过程中出现故障，nginx会把上传切到另一台服务器重新处理，而lvs就直接断掉了
	
	lvs的特点：
	A. 抗负载能力强，因为lvs工作方式的逻辑是非常之简单，而且工作在网络4层仅做请求分发之用，没有流量，所以在效率上基本不需要太过考虑。
	B. 配置性低，这通常是一大劣势，但同时也是一大优势，因为没有太多可配置的选项，所以除了增减服务器，并不需要经常去触碰它，大大减少了人为出错的几率。
	C. 工作稳定，因为其本身抗负载能力很强，所以稳定性高也是顺理成章，另外各种lvs都有完整的双机热备方案，所以一点不用担心均衡器本身会出什么问题，
	   节点出现故障的话，lvs会自动判别，所以系统整体是非常稳定的。
	D. 无流量，上面已经有所提及了。lvs仅仅分发请求，而流量并不从它本身出去，所以可以利用它这点来做一些线路分流之用。没有流量同时也保住了均衡器的IO性能不会受到大流量的影响。
	E. 基本上能支持所有应用，因为lvs工作在4层，所以它可以对几乎所有应用做负载均衡，包括http、数据库、聊天室等等。
	
	Nginx的特点是：
	A. 工作在网络的7层之上，可以针对http应用做一些分流的策略，比如针对域名、目录结构，它的正则规则比HAProxy更为强大和灵活，这也是它目前广泛流行的主要原因之一
	B. Nginx对网络稳定性的依赖非常小，理论上能ping通就就能进行负载功能，这个也是它的优势之一；相反LVS对网络稳定性依赖比较大，这点本人深有体会；
	C. Nginx安装和配置比较简单，测试起来比较方便，它基本能把错误用日志打印出来。LVS的配置、测试就要花比较长的时间了，LVS对网络依赖比较大。
	D. 可以承担高负载压力且稳定，在硬件不差的情况下一般能支撑几万次的并发量，负载度比LVS相对小些。
	E. Nginx可以通过端口检测到服务器内部的故障，比如根据服务器处理网页返回的状态码、超时等等，并且会把返回错误的请求重新提交到另一个节点，不过其中缺点就是不支持url来检测。
	比如用户正在上传一个文件，而处理该上传的节点刚好在上传过程中出现故障，Nginx会把上传切到另一台服务器重新处理，而LVS就直接断掉了，如果是上传一个很大的文件或者很重要的文件的话，
	用户可能会因此而不满。
	F. Nginx不仅仅是一款优秀的负载均衡器/反向代理软件，它同时也是功能强大的Web应用服务器。LNMP也是近几年非常流行的web架构，在高流量的环境中稳定性也很好。
	G. Nginx现在作为Web反向加速缓存越来越成熟了，速度比传统的Squid服务器更快，可以考虑用其作为反向代理加速器。
	H. Nginx也可作为静态网页和图片服务器，这方面的性能也无对手。还有Nginx社区非常活跃，第三方模块也很多。
	I. Nginx新版本已经支持代理tcp各种协议，不再仅仅局限在代理http、https以及email。

### 3.你常用的Nginx模块，用来做什么?

	rewrite模块，实现重写功能
	access模块：来源控制
	ssl模块：安全加密
	ngx_http_gzip_module：网络传输压缩模块
	ngx_http_proxy_module 模块实现代理
	ngx_http_upstream_module模块实现定义后端服务器列表
	ngx_cache_purge实现缓存清除功能

### 4.nginx的优化有哪些?

	隐藏版本信息
	nginx事件处理模型优化
	优化绑定不同的nginx进程到不同的CPU上
	优化nginx进程个数的策略
	FastCGI相关参数调优
	配置nginx gzip压缩实现性能优化

### 5.nginx有哪几种调度算法，解释一下ip hash和轮询有啥不一样？

	常用的有3种调度算法（轮询、ip hash、权重）。
	
	轮询：upstream按照轮询（默认）方式进行负载，每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。
	
	ip hash：每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。
	
	权重：指定轮询几率，权重（weight）和访问比率成正比，用于后端服务器性能不均的情况。

### 6.nginx你用到了哪些模块，在proxy模块中你配置过哪些参数？

	用到过（负载均衡upstream、反向代理proxy_pass、location、rewrite等）。
	
	proxy模块中配置过:proxy_set_header、proxy_connect_timeout、proxy_send_timeout

### 7.nginx中rewrite有哪几个flag标志位（last、break、redirect、permanent），说一下都什么意思？

	last : 相当于Apache的[L]标记，表示完成当前的rewrite规则
	break : 停止执行当前虚拟主机的后续rewrite指令集
	redirect : 返回302临时重定向，地址栏会显示跳转后的地址
	permanent : 返回301永久重定向，地址栏会显示跳转后的地址
	301和302不能简单的只返回状态码，还必须有重定向的URL，这就是return指令无法返回301,302的原因了。这里 last 和 break 区别有点难以理解：
	
		last一般写在server和if中，而break一般使用在location中
		last不终止重写后的url匹配，即新的url会再从server走一遍匹配流程，而break终止重写后匹配
		break和last都能组织继续执行后面的rewrite指令


### 8.nginx中location匹配顺序？

	匹配优先级：=，^~，~/~*，不带符号
	
	location = / {
	[ configuration A ]
	}
	
	location / {
	    [ configuration B ]
	}
	
	location /user/ {
	    [ configuration C ]
	}
	
	location ^~ /images/ {
	    [ configuration D ]
	}
	
	location ~* \.(gif|jpg|jpeg)$ {
	    [ configuration E ]
	}


	请求/精准匹配A，不再往下查找。
	
	请求/index.html匹配B。首先查找匹配的前缀字符，找到最长匹配是配置B，接着又按照顺序查找匹配的正则。结果没有找到，因此使用先前标记的最长匹配，即配置B。
	
	请求/user/index.html匹配C。首先找到最长匹配C，由于后面没有匹配的正则，所以使用最长匹配C。
	
	请求/user/1.jpg匹配E。首先进行前缀字符的查找，找到最长匹配项C，继续进行正则查找，找到匹配项E。因此使用E。
	
	请求/images/1.jpg匹配D。首先进行前缀字符的查找，找到最长匹配D。但是，特殊的是它使用了^~修饰符，不再进行接下来的正则的匹配查找，因此使用D。这里，如果没有前面的修饰符，其实最终的匹配是E。大家可以想一想为什么。
	
	请求/documents/about.html匹配B。因为B表示任何以/开头的URL都匹配。在上面的配置中，只有B能满足，所以匹配B。



## LVS
### 1.LVS三种负载均衡技术？

	VS/NAT模式：也就是网络地址转换技术实现虚拟服务器，当用户请求到达调度器时，调度器将请求报文的目标地址（即虚拟IP地址）改写成选定的Real Server地址，
			   同时报文的目标端口也改成选定的Real Server的相应端口，最后将报文请求发送到选定的Real Server。在服务器端得到数据后，Real Server返回数据给用户时，
			   需要再次经过负载调度器将报文的源地址和源端口改成虚拟IP地址和相应端口，然后把数据发送给用户，完成整个负载调度过程。
			   可以看出，在NAT方式下，用户请求和响应报文都必须经过Director Server地址重写，当用户请求越来越多时，调度器的处理能力将称为瓶颈。
	VS/TUN模式：就是IP隧道技术实现虚拟服务器。它的连接调度和管理与VS/NAT方式一样，只是它的报文转发方法不同，VS/TUN方式中，
			   调度器采用IP隧道技术将用户请求转发到某个Real Server，而这个Real Server将直接响应用户的请求，不再经过前端调度器，此外，对Real Server的地域位置没有要求，
			   可以和Director Server位于同一个网段，也可以是独立的一个网络。因此，在TUN方式中，调度器将只处理用户的报文请求，集群系统的吞吐量大大提高。
			   这种调度方式下，Real Server必须能与客户端进行通信，且Real Server需配置VIP
	VS/DR模式：也就是用直接路由技术实现虚拟服务器。它的连接调度和管理与VS/NAT和VS/TUN中的一样，但它的报文转发方法又有不同，VS/DR通过改写请求报文的目的MAC地址，
			   将请求发送到Real Server，而Real Server将响应直接返回给客户，免去了VS/TUN中的IP隧道开销。这种方式是三种负载调度机制中性能最高最好的，
			   但是必须要求Director Server与Real Server都有一块网卡连在同一物理网段上。

### 2.LVS负载均衡算法？

	回答负载调度算法，IPVS实现在八种负载调度算法，我们常用的有四种调度算法（轮叫调度、加权轮叫调度、最少链接调度、加权最少链接调度）。
	
	轮叫调度（Round-Robin Scheduling）
	加权轮叫调度（Weighted Round-Robin Scheduling）
	最小连接调度（Least-Connection Scheduling）
	加权最小连接调度（Weighted Least-Connection Scheduling）
	基于局部性的最少链接（Locality-Based Least Connections Scheduling）
	带复制的基于局部性最少链接（Locality-Based Least Connections with Replication Scheduling）
	目标地址散列调度（Destination Hashing Scheduling）
	源地址散列调度（Source Hashing Scheduling）


## KeepAlived
### 1.Keepalive的工作原理和如何做到健康检查?

	Keepalived是以VRRP协议为实现基础的，VRRP全称 Virtual Router Redundancy Protocol，即虚拟路由冗余协议。
	
	虚拟路由冗余协议，可以认为是实现路由器高可用的协议，即将N台提供相同功能的路由器组成一个路由器组，这个组里面有一个master和多个backup，
	master上面有一个对外提供服务的vip（该路由器所在局域网内其他机器的默认路由为该vip），master会发组播，当backup收不到vrrp包时就认为master宕掉了，
	这时就需要根据VRRP的优先级来选举一个backup当master。这样的话就可以保证路由器的高可用了。
	
	在一个虚拟路由器中，只有作为MASTER的VRRP路由器会一直发送VRRP通告信息,BACKUP不会抢占MASTER，除非它的优先级更高。当MASTER不可用时(BACKUP收不到通告信息)
	多台BACKUP中优先级最高的这台会被抢占为MASTER。这种抢占是非常快速的(<1s)，以保证服务的连续性，由于安全性考虑，VRRP包使用了加密协议进行加密。
	BACKUP不会发送通告信息，只会接收通告信息
	
	keepalived主要有三个模块，分别是core、check和vrrp。
	core模块为keepalived的核心，负责主进程的启动、维护以及全局配置文件的加载和解析。
	check负责健康检查，包括常见的各种检查方式。
	vrrp模块是来实现VRRP协议的。

## Tomcat
### 1.讲述一下Tomcat8005、8009、8080三个端口的含义？

	8005：用于关闭tomcat
	8009：为AJP协议端口，即容器使用，如Apache能通过AJP协议访问Tomcat的8009端口
	8080：一般的web服务器使用http协议，如nginx可通过该端口访问tomcat服务。

## Apache
### 1.apache与nginx的优缺点

	nginx 相对 apache 的优点：
		轻量级，同样起web 服务，比apache 占用更少的内存及资源
		抗并发，nginx 处理请求是异步非阻塞的，而apache 则是阻塞型的，在高并发下nginx 能保持低资源低消耗高性能
		高度模块化的设计，编写模块相对简单
		社区活跃，各种高性能模块出品迅速啊
	
	apache 相对nginx 的优点：
		rewrite ，比nginx 的rewrite 强大
		模块超多，基本想到的都可以找到
		少bug ，nginx 的bug 相对较多
		超稳定

### 2.apache的三种工作模式

	prefork模式：prefork模式下，一个以root身份运行的主httpd进程(父进程)负责fork一堆以普通身份运行的子httpd进程。父进程只负责管理子进程，
	子进程才是负责监听和处理web请求的进程，当有请求到达，空闲的子进程会迎接该请求并和该客户端建立连接。
	prefork的缺点就是用进程去处理请求，相比于线程，进程太过重量级，对于繁忙的站点来说，不断处理新请求，就需要不断地在进程之间进行切换，进程切换动作对cpu来说是没有生产力的，
	切换太频繁会浪费很多cpu资源。另一方面，httpd的各子进程之间不共享内存，在一定程度上性能也够好。但它也有优点，基于进程的处理方式，稳定性和调节能力比较好。
	
	worker模式：worker模式是对prefork模式的改进，在进程方面，它和prefork一样，有root身份的父httpd进程，普通身份的子httpd进程。
	httpd启动时，初始化创建的子进程数量由StartServers指令决定(worker模式下默认为3)。但不同的是，在每个子进程下还有一堆线程。
	这些线程包括工作线程(worker thread)和一个额外的监听线程(listener thread)。
	监听线程负责轮询(poll模式)监控开放的服务端口，接收请求并建立连接，然后将连接套接字放入套接字队列中，当工作线程"闲"下来时，将套接字从套接字队列中读走并开始处理。
	每当工作线程闲下来，都会通知监听线程它当前空闲，这样一来，监听线程就知道它所在子进程中是否还有空闲的工作线程，如果没有空闲工作线程，即满负荷状态，
	则监听线程暂时不会去接受新连接请求，因为即使接进来放到套接字队列中，也没有工作线程可以立即处理它们。
	
	event模式：event模式的优点在前面就已经说了。它是在worker模式上改进的，也是"主进程-->子进程-->工作线程+监听线程"的方式。
	它改进的地方是使用了事件驱动IO复用模型(基于epoll)，强化了监听线程的工作能力。相比worker模式，它最直观的提升是大大改善了处理长连接(keep alive)的方式，可以一个线程处理多个连接请求。
	非event模式处理长连接的方式总会有占着茅坑不拉屎的浪费，而event模式下，当工作线程对某次请求的响应结束后，会将处于长连接状态的套接字交给监听线程。
	如果这个套接字的客户端没有继续发送请求，正常情况下会一直等到直到长连接超时，然后会关闭套接字，断开长连接。如果客户端又发送了请求，由于基于epoll，
	这个套接字会自己站出来告诉监听线程它有事件发生，于是监听线程会把这个套接字交给第一个空闲的工作线程。

## DNS
### 1.简述dns的查询过程	

	1.查看本地缓存、host文件是否有缓存记录
	2.查看本机指向的DNS服务器是否有域名缓存记录
	3.像顶级域 根域发起查询请求
	4.层层查找返回结果
	
	1-2递归查询（必须有结果）
	2-4迭代查询（一次一次查询直到有结果）

## CDN

### 1.什么是CDN？

	CDN，Content Distribute Network，可以直译成内容分发网络，CDN解决的是如何将数据快速可靠从源站传递到用户的问题。用户获取数据时，不需要直接从源站获取，通过CDN对于数据的分发，
	用户可以从一个较优的服务器获取数据，从而达到快速访问，并减少源站负载压力的目的。

### 2.为什么不直接让用户从源站拿取数据呢？

	我们常说的互联网实际上由两层组成，一层是以TCP/IP为核心的网络层即Internet（因特网），另一层则是以万维网WWW为代表的应用层。数据从服务器端交付到用户端，至少有4个地方可能会造成网络拥堵。
	1. “第一公里”，这是指万维网流量向用户传送的第一个出口，是网站服务器接入互联网的链路。这个出口带宽决定了一个网站能为用户提供的访问速度和并发访问量。当用户请求量超出网站的出口带宽，就会在出口处造成拥塞。
	2. “最后一公里”，万维网流量向用户传送的最后一段链路，即用户接入互联网的链路。用户接入的带宽影响用户接收流量的能力。随着电信运营商的大力发展，用户的接入带宽得到了很大改善，“最后一公里”问题基本得到解决。
	3. ISP互联，即因特网服务提供商之间的互联，比如中国电信和中国联通两个网络运营商之间的互联互通。当某个网站服务器部署在运营商A的机房，运营商B的用户要访问该网站，那就必须经过A、B之间的互联互通点进行跨网访问。
	   从互联网的架构来看，不同运营商之间的互联互通带宽，对任何一个运营商网络流量来说，占比都非常小。因此，这里也通常是网络传输的拥堵点。
	4. 长途骨干传输。首先是长距离传输时延问题，其次是骨干网络的拥塞问题，这些问题都会造成万维网流量传输的拥堵。
	
	从以上对于网络拥堵的情况分析，如果网络上的数据都使用从源站直接交付到用户的方法，那么将极有可能会出现访问拥塞的情况。
	如果能有一种技术方案，将数据缓存在离用户最近的地方，使用户以最快的速度获取，那这对于减少网站的出口带宽压力，减少网络传输的拥堵情况，将起到很大的作用。CDN正是这样一种技术方案。

### 3.CDN原理？

	1.当终端用户（北京）向www.a.com下的某资源发起请求时，首先向LDNS（本地DNS）发起域名解析请求。
	2.Local DNS检查缓存中是否有www.a.com的IP地址记录。如果有，则直接返回给终端用户；如果没有，则向授权DNS查询。
	3.当授权DNS解析www.a.com时，返回域名CNAME www.a.tbcdn.com对应IP地址。
	4.域名解析请求发送至阿里云DNS调度系统，并为请求分配最佳节点IP地址。
	5.Local DNS获取DNS返回的解析IP地址。
	6.用户获取解析IP地址。
	7.用户向获取的IP地址发起对该资源的访问请求。
		如果该IP地址对应的节点已缓存该资源，则会将数据直接返回给用户，例如，图中步骤7和8，请求结束。
		如果该IP地址对应的节点未缓存该资源，则节点向源站发起对该资源的请求。获取资源后，结合用户自定义配置的缓存策略，将资源缓存至节点，

## Redis

### 1.redis一共有多少个库，常用的数据类型?

	一共16个库（0-15），常用的数据类型有:string/list/set/hash/sorted

### 2.Redis的持久化方式有哪些？说说它们的区别？

	RDB:在指定的时间间隔内将内存中的数据集快照写入磁盘，也就是行话讲的Snapshot快照，它恢复时是将快照文件读到内存中。
		Redis会单独创建（fork）一个子进程来进行持久化，会先将数据写入到一个临时文件中，待持久化过程都结束了，再用这个临时文件替换上次持久化好的文件。
		整个过程中，主进程不进行任何IO操作，这就确保了极高的性能，如果需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那RDB方式要比AOF方式更加的高效。Redis默认使用RDB持久化。
	
		优点：
			1.RDB是一个非常紧凑的文件。
			2.RDB在保存RDB文件时父进程唯一需要做的就是fork出一个子进程，接下来的工作全由子进程来做，父进程不需要再做其他IO操作，所以RDB持久化方式可以最大化redis的性能。
			  与AOF相比，在恢复大数据集的时候，RDB方式会更快一些。
		缺点：      
			1.数据丢失风险大
			2.RDB需要经常fork子进程来保存数据集到硬盘上，当数据集比较大的时候，fork的过程是非常耗时的，可能会导致Redis在一些毫秒级不能响应客户端请求。


​	
​		客户端显示使用save或bgsave命令来手动启动快照保存机制：
​	
			SAVE：阻塞式的RDB持久化，当执行这个命令时redis的主进程把内存里的数据库状态写入到RDB文件（即上面的dump.rdb）中，直到该文件创建完毕的这段时间内redis将不能处理任何命令请求。
			BGSAVE：非阻塞式的持久化，它会创建一个子进程专门去把内存中的数据库状态写入RDB文件里，同时主进程还可以处理来自客户端的命令请求。
					但子进程基本是复制的父进程，这等于两个相同大小的redis进程在系统上运行，会造成内存使用率的大幅增加。
	
	AOF（Append Only File）：以日志的形式来记录每个写操作，将Redis执行过程的所有写指令记录下来（读操作不记录），只许追加文件但不可以改写文件，
		Redis启动之初会读取该文件重新构建数据，换言之，Redis重启的话就根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作。
	
		优点：
			1.AOF文件是一个只进行追加的日志文件
			2.Redis可以在AOF文件体积变得过大时，自动地在后台对AOF进行重写
			3.AOF文件有序地保存了对数据库执行的所有写入操作，这些写入操作以Redis协议的格式保存，因此AOF文件的内容非常容易被人读懂，对文件进行分析也很容易
		缺点：
			1.对于相同的数据集来说，AOF文件的体积通常要大于RDB文件的体积
			2.根据所使用的fsync策略，AOF的速度可能会慢于RDB

### 3.主从复制原理？

	Redis全量复制一般发生在Slave初始化阶段，这时Slave需要将Master上的所有数据都复制一份。具体步骤如下：
		1）从服务器连接主服务器，发送SYNC命令；
		2）主服务器接收到SYNC命名后，开始执行BGSAVE命令生成RDB文件并使用缓冲区记录此后执行的所有写命令；
		3）主服务器BGSAVE执行完后，向所有从服务器发送快照文件，并在发送期间继续记录被执行的写命令；
		4）从服务器收到快照文件后丢弃所有旧数据，载入收到的快照（全量复制）；
		5）主服务器快照发送完毕后开始向从服务器发送缓冲区中的写命令；
		6）从服务器完成对快照的载入，开始接收命令请求，并执行来自主服务器缓冲区的写命令（增量复制）；

### 4.Redis的高可用方案你了解哪些？

	sentinel：哨兵机制，3.0版本前
	redis-cluster：集群，3.0版本后
	redis+keepalived

### 5.列举redis支持的过期策略?

	定时过期：每个设置过期时间的key都需要创建一个定时器，到过期时间就会立即清除。该策略可以立即清除过期的数据，对内存很友好；
			 但是会占用大量的CPU资源去处理过期的数据，从而影响缓存的响应时间和吞吐量。
	惰性过期：只有当访问一个key时，才会判断该key是否已过期，过期则清除。该策略可以最大化地节省CPU资源，却对内存非常不友好。
			 极端情况可能出现大量的过期key没有再次被访问，从而不会被清除，占用大量内存。
	定期过期：每隔一定的时间，会扫描一定数量的数据库的expires字典中一定数量的key，并清除其中已过期的key。该策略是前两者的一个折中方案。
			 通过调整定时扫描的时间间隔和每次扫描的限定耗时，可以在不同情况下使得CPU和内存资源达到最优的平衡效果。
	
	Redis中同时使用了惰性过期和定期过期两种过期策略。

### 6.Redis的内存淘汰策略？

	Redis的内存淘汰策略是指在Redis的用于缓存的内存不足时，怎么处理需要新写入且需要申请额外空间的数据。
	
	noeviction：当内存不足以容纳新写入数据时，新写入操作会报错。
	allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key。
	allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个key。
	volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的key。
	volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个key。
	volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的key优先移除。

### 7.Redis集群实现原理？

	 Redis 集群键分布算法使用数据分片（sharding）而非一致性哈希（consistency hashing）来实现：
	 一个 Redis 集群包含 16384 个哈希槽（hash slot）， 它们的编号为0、1、2、3……16382、16383，这个槽是一个逻辑意义上的槽，实际上并不存在。
	 redis中的每个key都属于这 16384 个哈希槽的其中一个，存取key时都要进行key->slot的映射计算。它们任何两个master节点之间都是相互连通的（ping-pong）。
	 客户端可以与任何一个节点相连接，然后就可以访问集群中的任何一个节点，对其进行存取和其他操作。且每个master可有多个slaver，当master挂掉后slaver可以迅速顶替master，保证集群高可用性。

### 8.Redis有哪些架构模式？讲讲各自的特点

### 9.使用过Redis分布式锁么，它是怎么实现的？

### 10.使用过Redis做异步队列么，你是怎么用的？有什么缺点？

### 11.什么是缓存穿透？如何避免？什么是缓存雪崩？如何避免

### 12.为什么Redis单线程却能支撑高并发？

### 13.Redis的并发竞争问题如何解决？

### 14.如何查看redis设置的最大内存，在不重启redis的情况下如何调整最大内存？



## RabbitMQ

## Kafka

### 1.消息队列点对点模式以及发布订阅模式？

```c
点对点：消息生产者生产消息发送到queue中，然后消息消费者从queue中取出并且消费消息。这里要注意：消息被消费以后，queue中不再有存储，所以消息消费者不可能消费到已经被消费的消息。Queue支持存在多个消费者，但是对一个消息而言，只会有一个消费者可以消费。

发布/订阅：消息生产者（发布）将消息发布到topic中，同时有多个消息消费者（订阅）消费该消息。和点对点方式不同，发布到topic的消息会被所有订阅者消费。
```

### 2.kafka名词解释？

    Producer ：消息生产者，就是向kafka broker发消息的客户端。
    
    Consumer ：消息消费者，向kafka broker取消息的客户端
    
    Topic ：咋们可以理解为一个队列。
    
    Consumer Group （CG）：这是kafka用来实现一个topic消息的广播（发给所有的consumer）和单播（发给任意一个consumer）的手段。一个topic可以有多个CG。	topic的消息会复制（不是真的复制，是概念上的）到所有的CG，但每个CG只会把消息发给该CG中的一个consumer。如果需要实现广播，只要每个consumer有一个独立的CG就可以了。要实现单播只要所有的consumer在同一个CG。用CG还可以将consumer进行自由的分组而不需要多次发送消息到不同的topic。
    
    Broker ：一台kafka服务器就是一个broker。一个集群由多个broker组成。一个broker可以容纳多个topic。
    
    Partition：为了实现扩展性，一个非常大的topic可以分布到多个broker（即服务器）上，一个topic可以分为多个partition，每个partition是一个有序的队列。partition中的每条消息都会被分配一个有序的id（offset）。kafka只保证按一个partition中的顺序将消息发给consumer，不保证一个topic的整体（多个partition间）的顺序。
    
    Offset：kafka的存储文件都是按照offset.kafka来命名，用offset做名字的好处是方便查找。例如你想找位于2049的位置，只要找到2048.kafka的文件即可。当然the first offset就是00000000000.kafka
### 3.zookeeper对kafka集群的作用是什么？

```c
1、Broker注册
Broker是分布式部署并且相互之间相互独立，但是需要有一个注册系统能够将整个集群中的Broker管理起来，此时就使用到了Zookeeper。在Zookeeper上会有一个专门用来进行Broker服务器列表记录的节点：/brokers/ids

每个Broker在启动时，都会到Zookeeper上进行注册，即到/brokers/ids下创建属于自己的节点，如/brokers/ids/[0...N]。

Kafka使用了全局唯一的数字来指代每个Broker服务器，不同的Broker必须使用不同的Broker ID进行注册，创建完节点后，每个Broker就会将自己的IP地址和端口信息记录到该节点中去。其中，Broker创建的节点类型是临时节点，一旦Broker宕机，则对应的临时节点也会被自动删除。

2、Topic注册
在Kafka中，同一个Topic的消息会被分成多个分区并将其分布在多个Broker上，这些分区信息及与Broker的对应关系也都是由Zookeeper在维护，由专门的节点来记录，如：
/borkers/topics

Kafka中每个Topic都会以/brokers/topics/[topic]的形式被记录，如/brokers/topics/login和/brokers/topics/search等。Broker服务器启动后，会到对应Topic节点（/brokers/topics）上注册自己的Broker ID并写入针对该Topic的分区总数，如/brokers/topics/login/3->2，这个节点表示Broker ID为3的一个Broker服务器，对于"login"这个Topic的消息，提供了2个分区进行消息存储，同样，这个分区节点也是临时节点。

3、生产者负载均衡
由于同一个Topic消息会被分区并将其分布在多个Broker上，因此，生产者需要将消息合理地发送到这些分布式的Broker上，那么如何实现生产者的负载均衡，Kafka支持传统的四层负载均衡，也支持Zookeeper方式实现负载均衡。

(1) 四层负载均衡，根据生产者的IP地址和端口来为其确定一个相关联的Broker。通常，一个生产者只会对应单个Broker，然后该生产者产生的消息都发往该Broker。这种方式逻辑简单，每个生产者不需要同其他系统建立额外的TCP连接，只需要和Broker维护单个TCP连接即可。但是，其无法做到真正的负载均衡，因为实际系统中的每个生产者产生的消息量及每个Broker的消息存储量都是不一样的，如果有些生产者产生的消息远多于其他生产者的话，那么会导致不同的Broker接收到的消息总数差异巨大，同时，生产者也无法实时感知到Broker的新增和删除。

(2) 使用Zookeeper进行负载均衡，由于每个Broker启动时，都会完成Broker注册过程，生产者会通过该节点的变化来动态地感知到Broker服务器列表的变更，这样就可以实现动态的负载均衡机制。

4、消费者负载均衡
与生产者类似，Kafka中的消费者同样需要进行负载均衡来实现多个消费者合理地从对应的Broker服务器上接收消息，每个消费者分组包含若干消费者，每条消息都只会发送给分组中的一个消费者，不同的消费者分组消费自己特定的Topic下面的消息，互不干扰。

5、分区 与 消费者 的关系

消费组 (Consumer Group)：consumer group 下有多个 Consumer（消费者）。对于每个消费者组 (Consumer Group)，Kafka都会为其分配一个全局唯一的Group ID，Group 内部的所有消费者共享该 ID。订阅的topic下的每个分区只能分配给某个 group 下的一个consumer(当然该分区还可以被分配给其他group)。同时，Kafka为每个消费者分配一个Consumer ID，通常采用"Hostname:UUID"形式表示。

在Kafka中，规定了每个消息分区 只能被同组的一个消费者进行消费，因此，需要在 Zookeeper 上记录 消息分区 与 Consumer 之间的关系，每个消费者一旦确定了对一个消息分区的消费权力，需要将其Consumer ID 写入到 Zookeeper 对应消息分区的临时节点上，例如：
/consumers/[group_id]/owners/[topic]/[broker_id-partition_id]

其中，[broker_id-partition_id]就是一个 消息分区 的标识，节点内容就是该 消息分区 上 消费者的Consumer ID。

6、消息 消费进度Offset 记录
在消费者对指定消息分区进行消息消费的过程中，需要定时地将分区消息的消费进度Offset记录到Zookeeper上，以便在该消费者进行重启或者其他消费者重新接管该消息分区的消息消费后，能够从之前的进度开始继续进行消息消费。Offset在Zookeeper中由一个专门节点进行记录，其节点路径为:
/consumers/[group_id]/offsets/[topic]/[broker_id-partition_id]
节点内容就是Offset的值。

7、消费者注册
消费者服务器在初始化启动时加入消费者分组的步骤如下:

注册到消费者分组。每个消费者服务器启动时，都会到Zookeeper的指定节点下创建一个属于自己的消费者节点，例如/consumers/[group_id]/ids/[consumer_id]，完成节点创建后，消费者就会将自己订阅的Topic信息写入该临时节点。

对消费者分组中的消费者的变化注册监听。每个消费者都需要关注所属消费者分 中其他消费者服务器的变化情况，即对/consumers/[group_id]/ids节点注册子节点变化的Watcher监听，一旦发现消费者新增或减少，就触发消费者的负载均衡。

对Broker服务器变化注册监听。消费者需要对/broker/ids/[0-N]中的节点进行监听，如果发现Broker服务器列表发生变化，那么就根据具体情况来决定是否需要进行消费者负载均衡。

进行消费者负载均衡。为了让同一个Topic下不同分区的消息尽量均衡地被多个 消费者 消费而进行 消费者 与 消息 分区分配的过程，通常，对于一个消费者分组，如果组内的消费者服务器发生变更或Broker服务器发生变更，会发出消费者负载均衡。

```





## Ansible

### 1.ansible中常用的模块及作用？

	ping：测试主机连通性
	shell：在远程主机上执行命令，支持管道，command不支持
	copy：用于将文件复制到远程主机
	file：创建文件，创建连接文件，删除文件等
	yum：用于yum安装包
	cron：管理计划任务
	service：管理服务
	script：在远程主机上执行脚本
	...

## ELK Stack

## Zabbix

## Prometheus
## Jenkins
## Docker
### 1.docker的四种网络模式，及常用命令
```c
docker命令
	容器生命周期管理 — docker [run|start|stop|restart|kill|rm|pause|unpause]
	容器操作运维 — docker [ps|inspect|top|attach|events|logs|wait|export|port]
	容器rootfs命令 — docker [commit|cp|diff]
	镜像仓库 — docker [login|pull|push|search]
	本地镜像管理 — docker [images|rmi|tag|build|history|save|import]
	其他命令 — docker [info|version]

四种网络模型：
	closed:只有本地回环接口，不能访问外部网络。
	bridge:bridged 容器拥有两个接口（总是成对出现），一个是私有的本地回环接口，另一个私有接口通过网桥（docker0桥）连接到主机的其他容器，相当于把一个接口放在docker0桥上。
	joind:Joined容器隔离程度低于Bridged容器。joined容器共享一个网络栈（即拥有自己的mount，user，pid 这三个名称空间，共享IPC，net，UTS 这三个名称空间），在这种情况下，容器之间没有任何的隔离。这意味着更少的控制和安全。尽管这不是最安全的原型，但它是第一个打破容器之间界限的。
	open:Open容器非常的危险。他没有网络容器，并且对主机网络有完全的访问权。包括对重要主机服务的访问权。直接共享宿主机的网络名称空间。
```

### 2.Docker容器使用了Linux内核中提供的6种命名空间隔离：
```c
1) UTS命名空间负责主机名和域名的隔离，使得容器都拥有自己的主机名和域名，可以被看作一个独立的网络节点。
2) IPC命名空间负责信号量、消息队列和共享内存的隔离，其包含了系统IPC标示符以及实现POSIX消息队列的文件系统，使得同一个IPC命名空间下的进程彼此可见，不同的则相互不可见；
3) PID命名空间负责进程PID编号的隔离，不同的PID命名空间下的进程可以有相同的PID，每个PID命名空间都有独立的计数程序。
4) Network命名空间负责网络资源的隔离，这里的隔离并非真正意义的网络隔离，而是把容器的网络独立出来，如同一个独立的网络实体来与外部通信。
5) Mount命名空间负责挂载点的隔离，不同Mount命名空间下的文件结构发生变化互不影响。
6) User命名空间负责安全相关的标示符和属性的隔离，包括用户ID、用户组ID、root目录、密钥key以及特殊权限等，该命名空间技术支持进程在容器内外拥有不同级别的权限。
```

### 3.dockerfile的一些命令 
```c
FROM： FROM指令是最重的一个且必须为Dockerfile文件开篇的第一个非注释行，用于为映像文件构建过程指定基准镜像，后续的指令运行于此基准镜像所提供的运行环境。
COPY： 用于从Docker主机复制文件至创建的新映像文件
VOLUME： 用于在image中创建一个挂载点目录，以挂载Docker host上的卷或其它容器上的卷。
EXPOSE： 用于为容器打开指定要监听的端口以实现与外部通信，但不能指定宿主机的端口绑定。
RUN： 用于指定docker build过程中运行的程序，其可以是任何命令
CMD： 类似于RUN指令，CMD指令也可用于运行任何命令或应用程序，不过，二者的运行时间点不同，RUN指令运行于映像文件构建过程中，而CMD指令运行于基于Dockerfile构建出的新映像文件启动一个容器时，CMD指令的首要目的在于为启动的容器指定默认要运行的程序
ENTRYPOINT： 类似CMD指令的功能，用于为容器指定默认运行程序，从而使得容器像是一个单独的可执行程序，与CMD不同的是，由ENTRYPOINT启动的程序不会被docker run命令行指定的参数所覆盖，而且，这些命令行参数会被当作参数传递给ENTRYPOINT指定指定的程序。
HEALTHCHECK： 对容器进行健康状态检测。
```

### 4.Docker的架构图
```c
C/S架构：Docker Client 同 Docker Daemon 进行交互，其中主要的工作是通过 Daemon 来完成，包括拉取镜像、编译镜像、运行容器、发布容器等。
Docker Client 和 Docker Daemon 可以运行在同一个系统上，也可以通过远程方式进行访问。
```

### 5.Docker的镜像是如何运行成容器的？
```c
作为静态的镜像，如何才有能力转化为一个动态的 Docker 容器呢？此时，我们可以想象：第一，转化的依据是什么；第二，由谁来执行这个转化操作。

其实，转化的依据是每个镜像的 json 文件，Docker 可以通过解析 Docker 镜像的 json 的文件，获知应该在这个镜像之上运行什样的进程，应该为进程配置怎么样的环境变量，此时也就实现了静态向动态的转变。

谁来执行这个转化工作？答案是 Docker 守护进程。也许大家早就理解这样一句话：Docker 容器实质上就是一个或者多个进程，而容器的父进程就是 Docker 守护进程。这样的，转化工作的执行就不难理解了：Docker 守护进程手握 Docker 镜像的 json 文件，为容器配置相应的环境，并真正运行 Docker 镜像所指定的进程，完成 Docker 容器的真正创建。
```


### 6.Docker你熟悉是吧？你说说Docker的三个核心概念？
```c
镜像：Docker 镜像是一个特殊的文件系统，除了提供容器运行时所需的程序、库、资源、配置等文件外，还包含了一些为运行时准备的一些配置参数（如匿名卷、环境变量、用户等）。镜像不包含任何动态数据，其内容在构建之后也不会被改变。通过联合文件系统分层构建，联合挂载，每一层都是只读层。docker 镜像是一个只读的 docker 容器模板，含有启动 docker 容器所需的文件系统结构及其内容，因此是启动一个 docker 容器的基础。docker 镜像的文件内容以及一些运行 docker 容器的配置文件组成了 docker 容器的静态文件系统运行环境：rootfs。
可以这么理解，docker 镜像是 docker 容器的静态视角，docker 容器是 docker 镜像的运行状态。

容器：容器是从镜像创建的应用运行实例，容器之间是相互隔离、互不可见的。可以把容器看做一个简易版的linux系统环境（包括root权限、进程空间、用户空间和网络空间等），以及运行在这个环境上的应用打包而成的应用盒子。镜像自身是只读的，容器从镜像启动的时候，docker会在镜像的最上层创建一个可写文件层，镜像本身保持不变。

仓库：就是保存镜像的空间，有公有仓库和私有仓库。
```

### 7.有什么方法可以将外部的数据挂载到容器中？对于臃肿的数据，我要怎么才能只挂载我需要的？
```c
容器挂载外部目录有两种方式：
1.容器自身管理的卷：即我们只需指定外部目录挂载在容器的哪个目录，会在宿主机上对应目录下生成一个随机目录用于挂载
2.自身管理的卷：我们指定宿主机上的哪个目录挂载到容器中的哪个目录下

可通过运行容器时使用 -v --volume 动态指定，也可在构建镜像时通过volume关键字指定，但这种方式只能使用容器自身管理的卷

```

### 8.Docker镜像管理如何做？我想在启动Docker容器的时候传入一些参数，怎么做？entrypoint和cmd的区别？别的用户怎么得知这个传入的参数呢？
```c
docker镜像管理可以通过打tag，上传镜像仓库进行管理

我们可以在启动容器的时候动态的传递参数，比如挂载哪个目录，开放哪个端口等等

RUN/CMD/ENTRYPOINT三个指令的区别：

	RUN：运行在docker build过程中，即从dockerfile变为image的过程中执行
	CMD：运行中docker run过程中，即从镜像文件转为容器的过程中，但是会被docker run动态指定的指令所覆盖
	ENTRYPOINT：与CMD类似，但是不会被docker run动态指定的指令覆盖，会把动态传递的指令当做参数传递给entrypoint指定的指令

用户可以通过docker inspect进行查看
```

### 9.Docker镜像删除命令？如何将所有镜像一次性删除？
```c
docker image rm 
docker rmi 

可写一个循环实现
```

### 10.什么是docker容器技术，docker与传统虚拟机有什么区别？以及docker的优点

### 11.docker镜像和层有什么区别？

### 12.docker容器有几种状态，如何查看docker容器的运行状态？

### 13.dockerfile中的copy和add命令有什么区别？
```c
copy和add都用于将docker主机上的文件复制到新镜像文件中
add指令与copy不同的是add支持使用tar文件和url路径，若使用本地tar文件，会被展开成目录复制进新镜像文件中，若是URL下的tar文件就不会被展开
```

## Kubernetes
### 1.简述创建pod的流程？
```c
创建pod流程：
1.客户提交创建请求，可以通过API server的Restful API，也可以通过kubectl命令行工具，也可使用配置文件，支持yaml和json格式
2.API server接收到pod请求后，不会直接去创建pod，存储pod数据到etcd
3.调度器通过API Server查看到未绑定的pod，尝试为pod分配主机，并将结果记录到etcd中
4.kubelet根据调度结果执行pod创建操作， 绑定成功后，scheduler会调用APIServer的API在etcd中创建一个boundpod对象，描述在一个工作节点上绑定运行的所有pod信息。运行在每个工作节点上的kubelet也会定期与etcd同步boundpod信息，一旦发现应该在该工作节点上运行的boundpod对象没有更新，则调用Docker API创建并启动pod内的容器。

创建replicaset：
1.客户提交创建请求
2.API server接收replicaset创建请求，将数据写入etcd中
3.controller-manager中的replicasetController在etcd数据库中读到新的replicaset信息后向k8s API server发起请求，创建几个pod，个数自己指定
4.调度器将pod调度到node，并将信息写到etcd中
5.kubelet创建pod，调度器会调用APIServer的API在etcd中创建一个boundpod对象，描述在一个工作节点上绑定运行的所有pod信息。运行在每个工作节点上的kubelet也会定期与etcd同步boundpod信息，一旦发现应该在该工作节点上运行的boundpod对象没有更新，则调用Docker API创建并启动pod内的容器。


注意：api server负责各个模块之间的通信。集群内的各个功能模块通过APIServer将信息存入etcd，当需要获取和操作这些数据时，则通过APIServer提供的REST接口（用GET、LIST或WATCH）来实现。

```
### 2.pod的生命周期各个阶段
```c
pending：这个阶段说明该pod已经被Kubernetes系统接收，但在调度完成之前需要准备相关的条件，比如下载镜像，创建网络登
Running：pod已经被调度到相应的node上，从调度层面上已经完成绑定，pod内所有容器已经创建完成，并且至少有一个容器处于运行状态，其他的处于启动或者重启状态，如果pod中所有容器都已经成功结束将不在执行重启动作
Succeeded：pod中所有的容器都已经成功借宿，并且将不会重启，例如job或者初始化任务
Failed：pod中所有容器都已经结束，并且至少有一个容器结束失败，所谓的结束失败值是容器的退出码不是0，或者是被系统强制退出的
Unknown：这个情况主要是由于无法获得pod的状态，常见的原因是无法和pod所在的主机进行通信

实际上还有一中状态Terminating，在代码和文档中都没有说明，但却是存在。这种情况出现杂无法获取所在主机的资源情况，一直在尝试建立连接。
```


### 3.k8s的master与node分别有哪些组件？有什么用？
```c
master：
	API Server：API Server是集群的核心组件，是集群的入口，无论我们是通过APIserver提供的restful api，还是kubectl，亦或是配置清单，都是通过APIserver操作的集群，通过APIserver我们才能往etcd中写入数据

	controller manager：控制器管理器，通过API Server监控etcd中的各节点信息，定时通过APIserver读取节点中的信息，这些信息是由kubelet定时推送给APIserver，并存入etcd中

	scheduler：Kubernetes的调度器，负责 Pod 资源调度。Scheduler监听API Server，当需要创建新的Pod时。Scheduler负责选择该Pod与哪个Node进行绑定。将此绑定信息通过API Server写入到Etcd中。若此时与Node A进行了绑定，那么A上的Kubelet就会从API Server上监听到此事件，那么该Kubelet就会做相应的创建工作。

	etcd：Etcd一种k-v存储仓库，可用于服务发现程序。在Kubernetes中就是用Etcd来存储各种k-v对象的。所以我也认为Etcd是Kubernetes的一个重要组件。当我们无论是创建Deployment也好，还是创建Service也好，各种资源对象信息都是写在Etcd中了。各个组件是通过API Server进行交流的，然而数据的来源是Etcd。所以维持Etcd的高可用是至关重要的。如果Etcd坏了，任何程序也无法正常运行了。


node：
	kubelet：Kubelet负责 Pod 对应的容器的创建，启动等任务，同时与Master节点密切协作。每个Node节点上都会有一个Kubelet负责Master下发到该节点的具体任务，管理该节点上的Pod和容器。而且会在创建之初向API Server注册自身的信息，定时汇报节点的信息。它还通过cAdvisor监控容器和节点资源。

	kube-proxy：实现 Kubernetes Service 的通信与负载均衡机制的重要组件。负责接收并转发请求。Kube-proxy的核心功能是将到Service的访问请求转发到后台的某个具体的Pod。无论是通过ClusterIP+Port的方式，还是NodeIP+NodePort的方式访问Service，最终都会被节点的Iptables规则重定向到Kube-proxy监听服务代理端口，该代理端口实际上就是SocketServer在本地随机打开的一个端口，SocketServer是Kube-proxy为每一个服务都会创建的“服务代理对象”的一部分。当Kube-proxy监听到Service的访问请求后，它会找到最适合的Endpoints，然后将请求转发过去。具体的路由选择依据Round Robin算法及Service的Session会话保持这两个特性。

	run container：一般使用docker
```


### 4.k8s的pause容器的作用？
```c
Pause容器 全称infrastucture container（又叫infra）基础容器。

每个Pod里运行着一个特殊的被称之为Pause的容器，其他容器则为业务容器，这些业务容器共享Pause容器的网络栈和Volume挂载卷，因此他们之间通信和数据交换更为高效，在设计时我们可以充分利用这一特性将一组密切相关的服务进程放入同一个Pod中。同一个Pod里的容器之间仅需通过localhost就能互相通信。

pause容器与应用容器共享网络名称空间(IPC,Network,PID)

```
### 5.k8s集群内pod应如何向外提供访问？
```c
service clusterIP：集群内负载，通信使用，外部无法访问
service nodeport：通过绑定宿主机端口与集群内service端口进行通信
service loadbalance：没用过
ingress：通过ingress暴露，若要外部访问还是需要给ingress做一个service nodeport
```



### 6.pod结束流程？

```c

1.用户发出删除 pod 命令
2.Pod 对象随着时间的推移更新，在宽限期（默认情况下30秒），pod 被视为“dead”状态
3.将 pod 标记为“Terminating”状态
4.第三步同时运行，监控到 pod 对象为“Terminating”状态的同时启动 pod 关闭过程
5.第三步同时进行，endpoints 控制器监控到 pod 对象关闭，将pod与service匹配的 endpoints 列表中删除
6.如果 pod 中定义了 preStop 钩子处理程序，则 pod 被标记为“Terminating”状态时以同步的方式启动执行；若宽限期结束后，preStop 仍未执行结束，第二步会重新执行并额外获得一个2秒的小宽限期
7.Pod 内对象的容器收到 TERM 信号
8.宽限期结束之后，若存在任何一个运行的进程，pod 会收到 SIGKILL 信号
9.Kubelet 请求 API Server 将此 Pod 资源宽限期设置为0从而完成删除操作

```

# 脚本运维

### 1.统计一下/var/log/nginx/access.log 日志中访问量最多的前十个IP?

```c
~]# cat access_log | awk ‘{print $1}’ | uniq -c |sort -rn | head -10

~]# awk '{print $1}' /var/log/nginx/access.log| sort | uniq -c | sort -nr -k1 | head -n 10
```



### 2.批量创建10个系统账号user01-user10并设置密码(密码为随机8位字符串)?

```c
(1)01-10
~]# echo {01..10}
~]# seq -w 10
    
(8)8位随机字符串
~]# echo $RANDOM | md5sum | cut -c 1-8
~]# openssl rand -base64 6
~]# date +%s%N | cut -c 1-8		#全为数字
~]# cat /proc/sys/kernel/random/uuid 
~]# head /dev/urandom | cksum | cut -c 1-8	#随机数字串

    
#!/bin/bash

. /etc/init.d/functions

for i in `seq -w 10`
do
    pass="`echo $RANDOM | md5sum | cut -c 2-9`"
    echo "$pass" >> /tmp/userpass.txt
    useradd user$i &> /dev/null
    echo $pass | passwd --stdin user$i &> /dev/null
    if [ $? -eq 0 ];then
        action "useradd user$i" /bin/true
    else
        action "useradd user$i" /bin/false
    fi
done
```

### 3.将/opt目录下的大于15KB的文件都移到/tmp目录下

```c
~]# find /opt/ -size +15k -exec mv {} /tmp/ \;
```

### 4.把/home目录下的大于10k的普通文件删除 

```c
~]# find /home -type f -size +10k -exec rm -f {} \; 
```

### 5.现有A文件，判断A文件中大于5的数字，并输出

```c
~]# for num in `cat A | tr '[a-zA-Z]' ' ' | sed 's/ /\n/g'`;do [ $num -gt 5 ]&&echo $num;done
~]# for num in `sed 's/[^0-9]/ /g' A | sed 's/ /\n/g'`;do [ $num -gt 5 ]&&echo $num;done 
```

### 6.在bash shell中$?,$#,$* 代表什么，其中$#和$*的区别

```c
$? 是显示最后命令的退出状态，0表示没有错误，其他表示有错误

$# 是传给脚本的参数个数

$@ 跟$*类似，但是可以当作数组用

$* 显示所有向脚本传递的参数

所以,$#是一个数字,而$*是一个字符串。

$0 这个程式的执行名字
$n 这个程式的第n个参数值，n=1..9
$$ 这个程式的PID(脚本运行的当前进程ID号)
$! 执行上一个背景指令的PID(后台运行的最后一个进程的进程ID号)
$- 显示shell使用的当前选项，与set命令功能相同
```

### 7.查看http的并发请求数与其TCP连接状态

```c
~]# netstat -tn | awk '/^tcp/ {b[$NF]++} END {for(a in b) print a,b[a]}'
```

### 8.查看/var/log下的普通文件数

```c
~]# ls /var/log/ -lR | grep '^-' | wc -l
```

### 9.每天晚上12点，打包目录/var/www/html 到/data 目录（每次按时间生成不同的备份包）
 ```c
#!/bin/bash

cd /var/www && tar czvf /data/html-`date +%Y%m%d`.tar.gz html/

~]# crontab -e
0 0 * * * /bin/sh /root/a.sh
 ```

### 10.请执行命令取出 linux 中 ens33 的 IP 地址
```
 ~]# ifconfig | sed -n '2p' | awk '{print $2}'
 ~]# ifconfig | sed -n '2p' | cut -d ' ' -f 10
 ~]# ifconfig | awk 'NR==2' | awk '{print $2}'
```

 ### 11.用正则表达式匹配IP地址
```c
~]# ifconfig | grep -o '[1-9]\{1\}[0-9]\{0,2\}\.[0-9]\{1,3\}.[0-9]\{1,3\}\.[0-9]\{1,3\}' 
~]# ifconfig | grep -o -E "([0-9]\.|[1-9][0-9]\.|1[0-9][0-9]\.|2[0-9][0-9]\.){3}([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-9]{2})"
```

 ### 12.检测httpd文件内容是否被篡改
 ```c
在网站文件上线时先给所有文件生成MD5值
~]# find /var/www/html -type f | xargs md5sum >> /tmp/md5list
~]# md5sum -c /tmp/md5list  #检测文件是否被篡改
~]# find /var/www/html -type f | wc -l #检测是否恶意增减文件
     
DIR=/var/www/html
MD5=/tmp/md5list
#dir is exist
[ ! -d $DIR ]&&{
    echo "$DIR is not exist"| mail -s "httpd alarm" root@localhost
}

if [ `md5sum -c $MD5 | grep "FAILED" | wc -l` -ne 0 ];then
    echo "httpd file is danger"
else
    echo "httpd file is OK"
fi
 ```

 ### 13.取变量或字符串长度方法
 ```c
~]# a=abcdef
~]# echo $a | wc -c    #包含了\0，实际应该减少1
~]# echo ${#a}      
~]# expr length "$a"
 ```

### 14.如何进行整数的计算

```
expr a++
((a++))
let a++
echo 5+3.5|bc
```

 ### 15.使用一条命令输出1+2+3+4+5+6+7+8+9+10=55
```c
echo `echo {1..10} | tr " " "+"`=`echo {1..10} | tr " " "+" | bc`
echo `seq -s "+" "10"`=`seq -s "+" "10" | bc`
```

 ### 16.判断网站url是否正常
```
#!/bin/bash
RETVAL=0

[ ! -f /etc/init.d/functions ]&&{
    echo "/etc/init.d/functions is not exist"
    exit 1
}
. /etc/init.d/functions

usage()
{
    echo "Usage:$0 url"
    exit 1
}
#check url func
check_url()
{
    wget -T 10 --spider -t 2 $1 &> /dev/null
    #curl -s -o /dev/null www.baidu.com
    #curl -m 3 --head www.baiu.com | grep 200 &> /dev/null 
    RETVAL=$?
    if [ $RETVAL -eq 0 ];then
        action "$1 url" /bin/true
    else
        action "$1 url" /bin/false
    fi
}

main() 
{
    if [ $# -ne 1 ];then
        usage
    fi
    check_url $1
}

main $*

https://cloud.tencent.com/developer/article/1150915
```

 ### 17.输出颜色字符
 ```c
#!/bin/bash
RED="\033[31m"
GREEN="\033[32m"
YELLOW="\033[33m"
BLUE="\033[34m"
PINK="\033[35m"
RES="\033[0m"

usage()
{
    echo "USAGE:$0 |red|green|yellow|blue|pink"
    exit 1
}

if [ $# -ne 1 ];then
    usage
fi

case $1 in
    red)
        echo -e "$RED hello red $RES"
        ;;
    green)
        echo -e "$GREEN hello green $RES"
        ;;
    yellow)
        echo -e "$YELLOW hello yellow $RES"
        ;;
    blue)
        echo -e "$BLUE hello blue $RES"
        ;;
    pink)
        echo -e "$PINK hello pink $RES"
        ;;
    *)
        usage
esac
 ```

 ### 18.从文件逐行读取内容
 ```c
方法一:
while read line
do
  echo $line
done < filename
     
方法二:
exec < filename
while read line
do
  echo $line
done
 ```

 ### 19.批量创建文件,随机八个字符，以_finsh.html结尾，且批量修改文件名称
 ```c
#!/bin/bash
DIR=~/test

[ ! -d $DIR ]&&{
    mkdir -p $DIR
    echo "$DIR mkdir success."
}

#create file.html
for i in `seq 10`
do
    touch $DIR/`echo $RANDOM | md5sum | cut -c 1-8`_finsh.html
    [ $? -eq 0 ]&&{
        echo "file create success."
    }
done

#change file_finsh.html to file.jpg
for j in `ls $DIR/*.html`
do
   mv $j `echo $j | sed 's/_finsh.html/.jpg/g'`
#   ls | awk -F '_' '{print "mv " $0,$1".jpg"}' | bash
#   rename "_finsh.html" ".jpg" $i
done
 ```

 ### 20.当内存小于等于100M时报警，并发送邮件给管理员
```
#!/bin/bash
#mem alarm
#get mem
mem=`free -m|grep "Mem"|awk '{print $NF}'`
#compare
if [ $mem -gt 100 ];then
    echo "mem is ok"
else
    echo "current mem is $mem."|mail -s "mem alarm" root@localhost
fi
```




 ### 21.写一个脚本解决DOS攻击生产案例
```
提示：根据web日志或者或者网络连接数，监控当某个IP并发连接数或者短时内PV达到100，即调用防火墙命令封掉对应的IP，监控频率每隔3分钟。
防火墙命令为：iptables -I INPUT -s 10.0.1.10 -j DROP。
 
#!/bin/bash

FILE_LOG=/var/log/httpd/access_log
#cat $FILE_LOG | awk '{print $1}' | sort | uniq -c > /tmp/ip.txt
exec < /tmp/ip.txt
while read line
do
  pv=`echo $line | awk '{print $1}'` 
  ip=`echo $line | awk '{print $2}'`
  if [ $pv -gt 100 -a `iptables -L | grep -w "$ip" | wc -l` -eq 0 ];then
    iptables -I INPUT -s $ip -j DROP
    [ $? -eq 0 ]&&{
        echo "drop $ip success."
    }
  fi
done
```




### 22.已知下面的字符串是通过RANDOM随机数变量md5sum|cut-c 1-8截取后的结果，请破解这些字符串对应的md5sum前的RANDOM对应数字？
```c
 21029299
 00205d1c
 a3da1677
 暴力破解，由于random随机生成1-32000多
     
#!/bin/bash

for n in `seq 33000`
do
  md5=`echo $RANDOM | md5sum | cut -c 1-8`
  if [ "$md5" == "$1" ];then
    echo "$n yes"    
    exit
  fi
    echo "$n no"
done
```

 ### 23.实现mysql数据库的分库分表备份
```c
#!/bin/bash
USER=root
PASS=960711
SOCKET=/var/lib/mysql/mysql.sock
CMD="mysql -u$USER -p$PASS -S $SOCKET"
DUMP="mysqldump -u$USER -p$PASS"
DBLIST=`$CMD -e "show databases;" | sed 1d | egrep -v "schema"`
DIR=/tmp

. /etc/init.d/functions

for dbname in $DBLIST
do
 #  $DUMP $dbname > $DIR/${dbname}_`date +%F`.sql
  TLIST=`$CMD -e "show tables from $dbname;" | sed 1d`  
  for tname in $TLIST
  do
    [ ! -d $DIR/$dbname ] && mkdir -p $DIR/$dbname
    $DUMP $dbname $tname > $DIR/$dbname/${tname}_`date +%F`.sql
    if [ $? -eq 0 ];then
      action "$dbname $tname dump" /bin/true
    else
      action "$dbnaem $tname dump" /bin/false
    fi
  done
done
```




### 24.排序
```c
1、按单词出现频率降序排序！
2、按字母出现频率降序排序！
 The months of learning in Old Boy education are the few months that I think the time efficient is the most.I had also studied at other training institutions before,but I was hard to understand what the tutor said and hard to follow.It was just too much to learn with no outline.
     
string=The months of learning in Old Boy education are the few months that I think the time efficient is the most.I had also studied at other training institutions before, but I was hard to understand what the tutor said and hard to follow. It was just too much to learn with no outline.

方法很多，大家自己试验
~]# echo $string | sed 's/ /\n/g' | tr ".|," " " | sort | uniq -c | sort -nr
~]# echo $string | sed 's/[ ,.]//g' | grep -o "." | sort | uniq -c | sort -nr
```

### 25.处理以下文件内容,将域名取出并进行计数排序
```
http://www.etiantian.org/index.html
http://www.etiantian.org/1.html
http://post.etiantian.org/index.html
http://mp3.etiantian.org/index.html
http://www.etiantian.org/3.html
http://post.etiantian.org/2.html
将域名先放入文件 domain.txt
 
~]# awk -F "/" '{S[$3]+=1}END{for(k in S) print k,S[k]}' domain.txt | sort -k2
```

### 26.有如下文本:

a 1
b 3
c 2
d 7
b 5
a 3
g 2
f 6
f 9
d 9
输出为:
d 16
f 15
b 8
a 4
g 2
c 2

```

~]# awk '{S[$1]+=$2}END{for(k in S) print k,S[k]}' test.txt | sort -nr -k2
```




 ### 27.删除一个文件中行号为奇数的行
 ```c
~]# sed '1~2'd file
 ```

### 28.打印1-100奇数
```
~]# seq 1 2 100
```

### 29.使用tcpdump监听主机为192.168.1.1，tcp端口为80的数据，并将输出结果保存输出到dump.log

```c
~]# tcpdump 'host 192.168.1.1 and port 80' > tcpdump.log
```

### 30.如何将本地80 端口的请求转发到8080 端口，当前主机IP 为192.168.2.1

```c
~]# iptables 
```











