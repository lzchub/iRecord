#docker
##1.docker的四种网络模式，及常用命令
```
docker命令
	容器生命周期管理 — docker [run|start|stop|restart|kill|rm|pause|unpause]
	容器操作运维 — docker [ps|inspect|top|attach|events|logs|wait|export|port]
	容器rootfs命令 — docker [commit|cp|diff]
	镜像仓库 — docker [login|pull|push|search]
	本地镜像管理 — docker [images|rmi|tag|build|history|save|import]
	其他命令 — docker [info|version]

四种网络模型：
	closed:只有本地回环接口，不能访问外部网络。
	bridge:bridged 容器拥有两个接口（总是成对出现），一个是私有的本地回环接口，另一个私有接口通过网桥（docker0桥）连接到主机的其他容器，相当于把一个接口放在docker0桥上。
	joind:Joined容器隔离程度低于Bridged容器。joined容器共享一个网络栈（即拥有自己的mount，user，pid 这三个名称空间，共享IPC，net，UTS 这三个名称空间），
		在这种情况下，容器之间没有任何的隔离。这意味着更少的控制和安全。尽管这不是最安全的原型，但它是第一个打破容器之间界限的。
	open:Open容器非常的危险。他没有网络容器，并且对主机网络有完全的访问权。包括对重要主机服务的访问权。直接共享宿主机的网络名称空间。
```
##2.Docker容器使用了Linux内核中提供的6种命名空间隔离：
```
1) UTS命名空间负责主机名和域名的隔离，使得容器都拥有自己的主机名和域名，可以被看作一个独立的网络节点。
2) IPC命名空间负责信号量、消息队列和共享内存的隔离，其包含了系统IPC标示符以及实现POSIX消息队列的文件系统，使得同一个IPC命名空间下的进程彼此可见，不同的则相互不可见；
3) PID命名空间负责进程PID编号的隔离，不同的PID命名空间下的进程可以有相同的PID，每个PID命名空间都有独立的计数程序。
4) Network命名空间负责网络资源的隔离，这里的隔离并非真正意义的网络隔离，而是把容器的网络独立出来，如同一个独立的网络实体来与外部通信。
5) Mount命名空间负责挂载点的隔离，不同Mount命名空间下的文件结构发生变化互不影响。
6) User命名空间负责安全相关的标示符和属性的隔离，包括用户ID、用户组ID、root目录、密钥key以及特殊权限等，该命名空间技术支持进程在容器内外拥有不同级别的权限。
```

##3.dockerfile的一些命令 
```
FROM： FROM指令是最重的一个且必须为Dockerfile文件开篇的第一个非注释行，用于为映像文件构建过程指定基准镜像，后续的指令运行于此基准镜像所提供的运行环境。
COPY： 用于从Docker主机复制文件至创建的新映像文件
VOLUME： 用于在image中创建一个挂载点目录，以挂载Docker host上的卷或其它容器上的卷。
EXPOSE： 用于为容器打开指定要监听的端口以实现与外部通信，但不能指定宿主机的端口绑定。
RUN： 用于指定docker build过程中运行的程序，其可以是任何命令
CMD： 类似于RUN指令，CMD指令也可用于运行任何命令或应用程序，不过，二者的运行时间点不同，RUN指令运行于映像文件构建过程中，
而CMD指令运行于基于Dockerfile构建出的新映像文件启动一个容器时，CMD指令的首要目的在于为启动的容器指定默认要运行的程序
ENTRYPOINT： 类似CMD指令的功能，用于为容器指定默认运行程序，从而使得容器像是一个单独的可执行程序，与CMD不同的是，
由ENTRYPOINT启动的程序不会被docker run命令行指定的参数所覆盖，而且，这些命令行参数会被当作参数传递给ENTRYPOINT指定指定的程序。
HEALTHCHECK： 对容器进行健康状态检测。

```

##4.Docker的架构图
```
C/S架构：Docker Client 同 Docker Daemon 进行交互，其中主要的工作是通过 Daemon 来完成，包括拉取镜像、编译镜像、运行容器、发布容器等。
Docker Client 和 Docker Daemon 可以运行在同一个系统上，也可以通过远程方式进行访问。
```
##5.Docker的镜像是如何运行成容器的？
```
作为静态的镜像，如何才有能力转化为一个动态的 Docker 容器呢？此时，我们可以想象：第一，转化的依据是什么；第二，由谁来执行这个转化操作。

其实，转化的依据是每个镜像的 json 文件，Docker 可以通过解析 Docker 镜像的 json 的文件，获知应该在这个镜像之上运行什样的进程，
应该为进程配置怎么样的环境变量，此时也就实现了静态向动态的转变。

谁来执行这个转化工作？答案是 Docker 守护进程。也许大家早就理解这样一句话：Docker 容器实质上就是一个或者多个进程，而容器的父进程就是 Docker 守护进程。
这样的，转化工作的执行就不难理解了：Docker 守护进程手握 Docker 镜像的 json 文件，为容器配置相应的环境，并真正运行 Docker 镜像所指定的进程，完成 Docker 容器的真正创建。
```

##6.Docker你熟悉是吧？你说说Docker的三个核心概念？
```
镜像：Docker 镜像是一个特殊的文件系统，除了提供容器运行时所需的程序、库、资源、配置等文件外，还包含了一些为运行时准备的一些配置参数（如匿名卷、环境变量、用户等）。镜像不包含任何动态数据，其内容在构建之后也不会被改变。通过联合文件系统分层构建，联合挂载，每一层都是只读层。docker 镜像是一个只读的 docker 容器模板，含有启动 docker 容器所需的文件系统结构及其内容，因此是启动一个 docker 容器的基础。docker 镜像的文件内容以及一些运行 docker 容器的配置文件组成了 docker 容器的静态文件系统运行环境：rootfs。可以这么理解，docker 镜像是 docker 容器的静态视角，docker 容器是 docker 镜像的运行状态。

容器：容器是从镜像创建的应用运行实例，容器之间是相互隔离、互不可见的。可以把容器看做一个简易版的linux系统环境（包括root权限、进程空间、用户空间和网络空间等），
以及运行在这个环境上的应用打包而成的应用盒子。镜像自身是只读的，容器从镜像启动的时候，docker会在镜像的最上层创建一个可写文件层，镜像本身保持不变。

仓库：就是保存镜像的空间，有公有仓库和私有仓库。

```

### 7.谈谈你对镜像的理解？

### 8.同一台服务器上有多个docker容器，如何让他们通信？dockerfile中应该怎么写，让docker容器能知道对方的ip?

### 9.有什么方法可以将外部的数据挂载到容器中？对于臃肿的数据，我要怎么才能只挂载我需要的？
```c
容器挂载外部目录有两种方式：
1.容器自身管理的卷：即我们只需指定外部目录挂载在容器的哪个目录，会在宿主机上对应目录下生成一个随机目录用于挂载
2.自身管理的卷：我们指定宿主机上的哪个目录挂载到容器中的哪个目录下

可通过运行容器时使用 -v --volume 动态指定，也可在构建镜像时通过volume关键字指定，但这种方式只能使用容器自身管理的卷

```

### 10.Docker镜像管理如何做？我想在启动Docker容器的时候传入一些参数，怎么做？entrypoint和cmd的区别？别的用户怎么得知这个传入的参数呢？
```c
docker镜像管理可以通过打tag，上传镜像仓库进行管理

我们可以在启动容器的时候动态的传递参数，比如挂载哪个目录，开放哪个端口等等

RUN/CMD/ENTRYPOINT三个指令的区别：

	RUN：运行在docker build过程中，即从dockerfile变为image的过程中执行
	CMD：运行中docker run过程中，即从镜像文件转为容器的过程中，但是会被docker run动态指定的指令所覆盖
	ENTRYPOINT：与CMD类似，但是不会被docker run动态指定的指令覆盖，会把动态传递的指令当做参数传递给entrypoint指定的指令

用户可以通过docker inspect进行查


```

### 11.Docker镜像删除命令？如何将所有镜像一次性删除？
```c
docker image rm 
docker rmi 

可写一个循环实现
```



### 12.什么是docker容器技术，docker与传统虚拟机有什么区别？以及docker的优点

### 13.docker镜像和层有什么区别？

### 14.docker容器有几种状态，如何查看docker容器的运行状态？


#CDN

##1.介绍CDN的作用
```
CDN加速简单的来说，就是把原服务器上数据复制到其他服务器上，用户访问时，那台服务器近访问到的就是那台服务器上的数据。
CDN加速优点是成本低，速度快。可以用CDN best的CDN进行加速，免费，可部署私有，公有CDN系统。可以实现宕机检测，自动切换ip，分线路，分组解析。
也就是CDN加速的主要作用就是保证网站的正常访问，及加快网站访问速度和响应速度，防止网站因黑客攻击，DNS解析劫持故障等导致的网站服务器的宕机状况的出现。
```
##2.CDN的实现机制
```

```
#LVS、KeepAlived、HAProxy、Nginx
##1.keepalive的工作原理和如何做到健康检查
```
keepalived是以VRRP协议为实现基础的，VRRP全称Virtual Router Redundancy Protocol，即虚拟路由冗余协议。

虚拟路由冗余协议，可以认为是实现路由器高可用的协议，即将N台提供相同功能的路由器组成一个路由器组，这个组里面有一个master和多个backup，
master上面有一个对外提供服务的vip（该路由器所在局域网内其他机器的默认路由为该vip），master会发组播，当backup收不到vrrp包时就认为master宕掉了，
这时就需要根据VRRP的优先级来选举一个backup当master。这样的话就可以保证路由器的高可用了。

在一个虚拟路由器中，只有作为MASTER的VRRP路由器会一直发送VRRP通告信息,BACKUP不会抢占MASTER，除非它的优先级更高。当MASTER不可用时(BACKUP收不到通告信息)
多台BACKUP中优先级最高的这台会被抢占为MASTER。这种抢占是非常快速的(<1s)，以保证服务的连续性，由于安全性考虑，VRRP包使用了加密协议进行加密。BACKUP不会发送通告信息，只会接收通告信息

keepalived主要有三个模块，分别是core、check和vrrp。core模块为keepalived的核心，负责主进程的启动、维护以及全局配置文件的加载和解析。
check负责健康检查，包括常见的各种检查方式。vrrp模块是来实现VRRP协议的。
```
##2.LVS有哪些负载均衡技术和调度算法?
```
LVS是Liunx虚拟服务器的简称，利用LVS提供的负载均衡技术和linux操作系统可实现高性能、高可用的服务器集群，一般LVS都是位于整个集群系统的最前端，
由一台或者多台负载调度器（Director Server）组成，分发给应用服务器（Real Server）。它是工作在4层（也就是TCP/IP中的传输层），
LVS是基于IP负载均衡技术的IPVS模块来实现的，IPVS实现负载均衡机制有三种，分别是NAT、TUN和DR.

NAT:也就是网络地址翻译技术实现虚拟服务器，当用户请求到达调度器时，调度器将请求报文的目标地址（即虚拟IP地址）改写成选定的Real Server地址，
同时报文的目标端口也改成选定的Real Server的相应端口，最后将报文请求发送到选定的Real Server。在服务器端得到数据后，Real Server返回数据给用户时，
需要再次经过负载调度器将报文的源地址和源端口改成虚拟IP地址和相应端口，然后把数据发送给用户，完成整个负载调度过程。
可以看出，在NAT方式下，用户请求和响应报文都必须经过Director Server地址重写，当用户请求越来越多时，调度器的处理能力将称为瓶颈。

TUN：就是IP隧道技术实现虚拟服务器。它的连接调度和管理与VS/NAT方式一样，只是它的报文转发方法不同，VS/TUN方式中，
调度器采用IP隧道技术将用户请求转发到某个Real Server，而这个Real Server将直接响应用户的请求，不再经过前端调度器，此外，对Real Server的地域位置没有要求，
可以和Director Server位于同一个网段，也可以是独立的一个网络。因此，在TUN方式中，调度器将只处理用户的报文请求，集群系统的吞吐量大大提高。

DR：也就是用直接路由技术实现虚拟服务器。它的连接调度和管理与VS/NAT和VS/TUN中的一样，但它的报文转发方法又有不同，VS/DR通过改写请求报文的MAC地址，
将请求发送到Real Server，而Real Server将响应直接返回给客户，免去了VS/TUN中的IP隧道开销。这种方式是三种负载调度机制中性能最高最好的，
但是必须要求Director Server与Real Server都有一块网卡连在同一物理网段上。

回答负载调度算法，IPVS实现在八种负载调度算法，我们常用的有四种调度算法（轮叫调度、加权轮叫调度、最少链接调度、加权最少链接调度）。
轮叫调度（Round-Robin Scheduling）
加权轮叫调度（Weighted Round-Robin Scheduling）
最小连接调度（Least-Connection Scheduling）
加权最小连接调度（Weighted Least-Connection Scheduling）
基于局部性的最少链接（Locality-Based Least Connections Scheduling）
带复制的基于局部性最少链接（Locality-Based Least Connections with Replication Scheduling）
目标地址散列调度（Destination Hashing Scheduling）
源地址散列调度（Source Hashing Scheduling）
```
##3.nginx的应用场景？
```
1、http服务器。Nginx是一个http服务可以独立提供http服务。可以做网页静态服务器。
2、虚拟主机。可以实现在一台服务器虚拟出多个网站，例如个人网站使用的虚拟机。
3、反向代理，负载均衡。当网站的访问量达到一定程度后，单台服务器不能满足用户的请求时，需要用多台服务器集群可以使用nginx做反向代理。
并且多台服务器可以平均分担负载，不会应为某台服务器负载高宕机而某台服务器闲置的情况。
```
##4.LVS、Nginx、HAproxy有什么区别？工作中你怎么选择？
```
LVS： 是基于四层的转发
HAproxy： 是基于四层和七层的转发，是专业的代理服务器
Nginx： 是WEB服务器，缓存服务器，又是反向代理服务器，可以做七层的转发

区别： LVS由于是基于四层的转发所以只能做端口的转发,而基于URL的、基于目录的这种转发LVS就做不了

工作选择：
HAproxy和Nginx由于可以做七层的转发，所以URL和目录的转发都可以做.
在很大并发量的时候我们就要选择LVS，像中小型公司的话并发量没那么大,选择HAproxy或者Nginx足已，由于HAproxy由是专业的代理服务器,配置简单，所以中小型企业推荐使用HAproxy

https://www.csdn.net/article/2014-07-24/2820837

```
##5.说说haproxy如何做调度的

##6.lvs与nginx负载均衡的区别
```
1）nginx工作在网络的七层，所以他可以针对http应用本身来做分流策略，比如针对域名，目录等，而lvs并不具备这些功能，所以nginx这点可利用的地方就多余lvs，
但因为这些功能使其调整度高于lvs，需要经常触碰，触碰多了，出问题的几率就会增加，而lvs配置性不高，没有太多的可配置选项，除了增减服务器，并不需要经常去触碰他，大大减少人为出错。
2）nginx对网络的依赖性比较小，理论上只要能ping通，网页访问正常，nginx就能连的通，lvs比较依赖于网络环境，至少需要一个公网ip来做VIP
3）nginx测试可以查看错误日志，而lvs出错，很多都是网络问题，没有错误日志，解决比较麻烦
4）nginx可以检测到服务器内部的故障，比如根据服务器处理网页返回的状态码、超时等等，并且会把返回错误的请求重新提交到另一个节点。
lvs的原理使其不能重发请求。比如用户正在上传一个文件，而处理该上传的节点刚 好在上传过程中出现故障，nginx会把上传切到另一台服务器重新处理，而lvs就直接断掉了

Nginx和lvs负载均衡比较

1)lvs的特点：
A. 抗负载能力强，因为lvs工作方式的逻辑是非常之简单，而且工作在网络4层仅做请求分发之用，没有流量，所以在效率上基本不需要太过考虑。
在我手里的 lvs，仅仅出过一次问题：在并发最高的一小段时间内均衡器出现丢包现象，据分析为网络问题，即网卡或linux2.4内核的承载能力已到上限，内存和 cpu方面基本无消耗。
B. 配置性低，这通常是一大劣势，但同时也是一大优势，因为没有太多可配置的选项，所以除了增减服务器，并不需要经常去触碰它，大大减少了人为出错的几率。
C. 工作稳定，因为其本身抗负载能力很强，所以稳定性高也是顺理成章，另外各种lvs都有完整的双机热备方案，所以一点不用担心均衡器本身会出什么问题，
节点出现故障的话，lvs会自动判别，所以系统整体是非常稳定的。
D. 无流量，上面已经有所提及了。lvs仅仅分发请求，而流量并不从它本身出去，所以可以利用它这点来做一些线路分流之用。没有流量同时也保住了均衡器的IO性能不会受到大流量的影响。
E. 基本上能支持所有应用，因为lvs工作在4层，所以它可以对几乎所有应用做负载均衡，包括http、数据库、聊天室等等。
另：lvs也不是完全能判别节点故障的，譬如在wlc分配方式下，集群里有一个节点没有配置VIP，会使整个集群不能使用，这时使用wrr分配方式则会丢掉一台机。
目前这个问题还在进一步测试中。所以，用lvs也得多多当心为妙。

Nginx的特点是：
A. 工作在网络的7层之上，可以针对http应用做一些分流的策略，比如针对域名、目录结构，它的正则规则比HAProxy更为强大和灵活，这也是它目前广泛流行的主要原因之一，
Nginx单凭这点可利用的场合就远多于LVS了。
B. Nginx对网络稳定性的依赖非常小，理论上能ping通就就能进行负载功能，这个也是它的优势之一；相反LVS对网络稳定性依赖比较大，这点本人深有体会；
C. Nginx安装和配置比较简单，测试起来比较方便，它基本能把错误用日志打印出来。LVS的配置、测试就要花比较长的时间了，LVS对网络依赖比较大。
D. 可以承担高负载压力且稳定，在硬件不差的情况下一般能支撑几万次的并发量，负载度比LVS相对小些。
E. Nginx可以通过端口检测到服务器内部的故障，比如根据服务器处理网页返回的状态码、超时等等，并且会把返回错误的请求重新提交到另一个节点，不过其中缺点就是不支持url来检测。
比如用户正在上传一个文件，而处理该上传的节点刚好在上传过程中出现故障，Nginx会把上传切到另一台服务器重新处理，而LVS就直接断掉了，如果是上传一个很大的文件或者很重要的文件的话，
用户可能会因此而不满。
F. Nginx不仅仅是一款优秀的负载均衡器/反向代理软件，它同时也是功能强大的Web应用服务器。LNMP也是近几年非常流行的web架构，在高流量的环境中稳定性也很好。
G. Nginx现在作为Web反向加速缓存越来越成熟了，速度比传统的Squid服务器更快，可以考虑用其作为反向代理加速器。
H. Nginx可作为中层反向代理使用，这一层面Nginx基本上无对手，唯一可以对比Nginx的就只有lighttpd了，不过lighttpd目前还没有做到Nginx完全的功能，配置也不那么清晰易读，社区资料也远远没Nginx活跃。
I. Nginx也可作为静态网页和图片服务器，这方面的性能也无对手。还有Nginx社区非常活跃，第三方模块也很多。
J. Nginx新版本已经支持代理tcp各种协议，不再仅仅局限在代理http、https以及email。
```

#DNS
##1.简述dns的查询过程
```
1.查看本地缓存、host文件是否有缓存记录
2.查看本机指向的DNS服务器是否有域名缓存记录
3.像顶级域 根域发起查询请求
4.层层查找返回结果

1-2递归查询（必须有结果）
2-4迭代查询（一次一次查询直到有结果）
```

#Httpd、Nginx、Tomcat
##1.apache与nginx的优缺点
```
nginx 相对 apache 的优点：
	轻量级，同样起web 服务，比apache 占用更少的内存及资源
	抗并发，nginx 处理请求是异步非阻塞的，而apache 则是阻塞型的，在高并发下nginx 能保持低资源低消耗高性能
	高度模块化的设计，编写模块相对简单
	社区活跃，各种高性能模块出品迅速啊

apache 相对nginx 的优点：
	rewrite ，比nginx 的rewrite 强大
	模块超多，基本想到的都可以找到
	少bug ，nginx 的bug 相对较多
	超稳定
```

##2.讲述一下Tomcat8005、8009、8080三个端口的含义？
```
8005：用于关闭tomcat
8009：为AJP协议端口，即容器使用，如Apache能通过AJP协议访问Tomcat的8009端口
8080：一般的web服务器使用http协议，如nginx可通过该端口访问tomcat服务。
```

##3.你常用的Nginx模块，用来做什么
```
rewrite模块，实现重写功能
access模块：来源控制
ssl模块：安全加密
ngx_http_gzip_module：网络传输压缩模块
ngx_http_proxy_module 模块实现代理
ngx_http_upstream_module模块实现定义后端服务器列表
ngx_cache_purge实现缓存清除功能
```

##4.对nginx熟悉哪个模块，介绍一下 

##5.nginx的优化有哪些；
```
隐藏版本信息
nginx事件处理模型优化
优化绑定不同的nginx进程到不同的CPU上
优化nginx进程个数的策略
FastCGI相关参数调优
配置nginx gzip压缩实现性能优化
...

https://www.cnblogs.com/dazhidacheng/p/7772451.html
```
##6.nginx有哪几种调度算法，解释一下ip hash和轮询有啥不一样？
```
常用的有3种调度算法（轮询、ip hash、权重）。

轮询：upstream按照轮询（默认）方式进行负载，每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。

ip hash：每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。

权重：指定轮询几率，权重（weight）和访问比率成正比，用于后端服务器性能不均的情况。
```

##7.nginx你用到了哪些模块，在proxy模块中你配置过哪些参数？
```
用到过（负载均衡upstream、反向代理proxy_pass、location、rewrite等）。

proxy模块中配置过:proxy_set_header、proxy_connect_timeout、proxy_send_timeout、
```

##8.apache的三种工作模式
```
prefork模式：prefork模式下，一个以root身份运行的主httpd进程(父进程)负责fork一堆以普通身份运行的子httpd进程。父进程只负责管理子进程，
子进程才是负责监听和处理web请求的进程，当有请求到达，空闲的子进程会迎接该请求并和该客户端建立连接。
prefork的缺点就是用进程去处理请求，相比于线程，进程太过重量级，对于繁忙的站点来说，不断处理新请求，就需要不断地在进程之间进行切换，进程切换动作对cpu来说是没有生产力的，
切换太频繁会浪费很多cpu资源。另一方面，httpd的各子进程之间不共享内存，在一定程度上性能也够好。但它也有优点，基于进程的处理方式，稳定性和调节能力比较好。

worker模式：worker模式是对prefork模式的改进，在进程方面，它和prefork一样，有root身份的父httpd进程，普通身份的子httpd进程。
httpd启动时，初始化创建的子进程数量由StartServers指令决定(worker模式下默认为3)。但不同的是，在每个子进程下还有一堆线程。
这些线程包括工作线程(worker thread)和一个额外的监听线程(listener thread)。
监听线程负责轮询(poll模式)监控开放的服务端口，接收请求并建立连接，然后将连接套接字放入套接字队列中，当工作线程"闲"下来时，将套接字从套接字队列中读走并开始处理。
每当工作线程闲下来，都会通知监听线程它当前空闲，这样一来，监听线程就知道它所在子进程中是否还有空闲的工作线程，如果没有空闲工作线程，即满负荷状态，
则监听线程暂时不会去接受新连接请求，因为即使接进来放到套接字队列中，也没有工作线程可以立即处理它们。

event模式：event模式的优点在前面就已经说了。它是在worker模式上改进的，也是"主进程-->子进程-->工作线程+监听线程"的方式。
它改进的地方是使用了事件驱动IO复用模型(基于epoll)，强化了监听线程的工作能力。相比worker模式，它最直观的提升是大大改善了处理长连接(keep alive)的方式，可以一个线程处理多个连接请求。
非event模式处理长连接的方式总会有占着茅坑不拉屎的浪费，而event模式下，当工作线程对某次请求的响应结束后，会将处于长连接状态的套接字交给监听线程。
如果这个套接字的客户端没有继续发送请求，正常情况下会一直等到直到长连接超时，然后会关闭套接字，断开长连接。如果客户端又发送了请求，由于基于epoll，
这个套接字会自己站出来告诉监听线程它有事件发生，于是监听线程会把这个套接字交给第一个空闲的工作线程。

```
#9.nginx中rewrite有哪几个flag标志位（last、break、redirect、permanent），说一下都什么意思？
```
last : 相当于Apache的[L]标记，表示完成当前的rewrite规则
break : 停止执行当前虚拟主机的后续rewrite指令集
redirect : 返回302临时重定向，地址栏会显示跳转后的地址
permanent : 返回301永久重定向，地址栏会显示跳转后的地址
301和302不能简单的只返回状态码，还必须有重定向的URL，这就是return指令无法返回301,302的原因了。这里 last 和 break 区别有点难以理解：

last一般写在server和if中，而break一般使用在location中
last不终止重写后的url匹配，即新的url会再从server走一遍匹配流程，而break终止重写后匹配
break和last都能组织继续执行后面的rewrite指令
```
#FTP
##1.ftp监听的端口，有什么模式 
```
FTP仅支持tcp，不支持udp。20（数据端口），21（控制端口）。
主动模式（PORT）和被动模式（PASV）。主动模式是从服务端向客户端发起连接；被动模式是客户端向服务器发起连接。
两者的共同点是都使用21端口进行用户验证及管理，差别在于传输数据的方式不同，PORT模式的FTP服务器数据端口固定在20，而PASV模式则在1025-65535之间。

```


#Squid、Varnish、Nginx
##.Squid、Varinsh和Nginx有什么区别，工作中你怎么选择？
```
Squid、Varinsh和Nginx都是代理服务器

什么是代理服务器：
能当替用户去访问公网，并且能把访问到的数据缓存到服务器本地，等用户下次再访问相同的资源的时候，代理服务器直接从本地回应给用户，当本地没有的时候，
我代替你去访问公网，我接收你的请求，我先在我自已的本地缓存找，如果我本地缓存有，我直接从我本地的缓存里回复你,如果我在我本地没有找到你要访问的缓存的数据，那么代理服务器就会代替你去访问公网 

区别：
1）Nginx本来是反向代理/web服务器，用了插件可以做做这个副业,但是本身不支持特性挺多，只能缓存静态文件
2）从这些功能上。varnish和squid是专业的cache服务，而nginx这些是第三方模块完成
3）varnish本身的技术上优势要高于squid，它采用了可视化页面缓存技术,在内存的利用上，Varnish比Squid具有优势，性能要比Squid高。
还有强大的通过Varnish管理端口，可以使用正则表达式快速、批量地清除部分缓存,它是内存缓存，速度一流，但是内存缓存也限制了其容量，缓存页面和图片一般是挺好的
4）squid的优势在于完整的庞大的cache技术资料，和很多的应用生产环境

工作中选择：
要做cache服务的话，我们肯定是要选择专业的cache服务，优先选择squid或者varnish。
```

#Redis
##1.redis集群怎么实现的，数据是怎么分片的
```
redis 3.0版本之前是不支持集群的，官方推荐最大的节点数量为1000，至少需要3(Master)+3(Slave)才能建立集群，是无中心的分布式存储架构，
可以在多个节点之间进行数据共享，解决了Redis高可用、可扩展等问题。集群可以将数据自动切分(split)到多个节点，当集群中的某一个节点故障时，redis还可以继续处理客户端的请求。

一个 Redis 集群包含 16384 个哈希槽（hash slot）， 它们的编号为0、1、2、3……16382、16383，这个槽是一个逻辑意义上的槽，实际上并不存在。
redis中的每个key都属于这 16384 个哈希槽的其中一个，存取key时都要进行key->slot的映射计算。它们任何两个master节点之间都是相互连通的（ping-pong）。
客户端可以与任何一个节点相连接，然后就可以访问集群中的任何一个节点，对其进行存取和其他操作。且每个master可有多个slaver，当master挂掉后slaver可以迅速顶替master，保证集群高可用性。
```
##2.redis主从，一共有多少个库，常用的数据类型?
```
一共16个库（0-15），常用的数据类型有:string/list/set/hash/sorted set

1）从服务器连接主服务器，发送SYNC命令；
2）主服务器接收到SYNC命名后，开始执行BGSAVE命令生成RDB文件并使用缓冲区记录此后执行的所有写命令；
3）主服务器BGSAVE执行完后，向所有从服务器发送快照文件，并在发送期间继续记录被执行的写命令；
4）从服务器收到快照文件后丢弃所有旧数据，载入收到的快照（全量复制）；
5）主服务器快照发送完毕后开始向从服务器发送缓冲区中的写命令；
6）从服务器完成对快照的载入，开始接收命令请求，并执行来自主服务器缓冲区的写命令（增量复制）；


```
##3.Redis的持久化方式有哪些？说说它们的区别
```
RDB:在指定的时间间隔内将内存中的数据集快照写入磁盘，也就是行话讲的Snapshot快照，它恢复时是将快照文件读到内存中。
Redis会单独创建（fork）一个子进程来进行持久化，会先将数据写入到一个临时文件中，待持久化过程都结束了，再用这个临时文件替换上次持久化好的文件。
整个过程中，主进程不进行任何IO操作，这就确保了极高的性能，如果需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那RDB方式要比AOF方式更加的高效。Redis默认使用RDB持久化。

优点：
	1.RDB是一个非常紧凑的文件。
	2.RDB在保存RDB文件时父进程唯一需要做的就是fork出一个子进程，接下来的工作全由子进程来做，父进程不需要再做其他IO操作，所以RDB持久化方式可以最大化redis的性能。
	与AOF相比，在恢复大数据集的时候，RDB方式会更快一些。
缺点：      
	1.数据丢失风险大
	2.RDB需要经常fork子进程来保存数据集到硬盘上，当数据集比较大的时候，fork的过程是非常耗时的，可能会导致Redis在一些毫秒级不能响应客户端请求。


客户端显示使用save或bgsave命令来手动启动快照保存机制：

SAVE：阻塞式的RDB持久化，当执行这个命令时redis的主进程把内存里的数据库状态写入到RDB文件（即上面的dump.rdb）中，直到该文件创建完毕的这段时间内redis将不能处理任何命令请求。
BGSAVE：非阻塞式的持久化，它会创建一个子进程专门去把内存中的数据库状态写入RDB文件里，同时主进程还可以处理来自客户端的命令请求。
但子进程基本是复制的父进程，这等于两个相同大小的redis进程在系统上运行，会造成内存使用率的大幅增加。

AOF（Append Only File）：以日志的形式来记录每个写操作，将Redis执行过程的所有写指令记录下来（读操作不记录），只许追加文件但不可以改写文件，
Redis启动之初会读取该文件重新构建数据，换言之，Redis重启的话就根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作。

优点：
	1.AOF文件是一个只进行追加的日志文件
	2.Redis可以在AOF文件体积变得过大时，自动地在后台对AOF进行重写
	3.AOF文件有序地保存了对数据库执行的所有写入操作，这些写入操作以Redis协议的格式保存，因此AOF文件的内容非常容易被人读懂，对文件进行分析也很容易
缺点：
	1.对于相同的数据集来说，AOF文件的体积通常要大于RDB文件的体积
	2.根据所使用的fsync策略，AOF的速度可能会慢于RDB

```
##4.Redis的高可用方案你了解哪些？
```
sentinel：哨兵机制
redis-cluster：集群
redis+keepalived：

```

##5.列举redis支持的过期策略。
```
定时过期：每个设置过期时间的key都需要创建一个定时器，到过期时间就会立即清除。该策略可以立即清除过期的数据，对内存很友好；
但是会占用大量的CPU资源去处理过期的数据，从而影响缓存的响应时间和吞吐量。
惰性过期：只有当访问一个key时，才会判断该key是否已过期，过期则清除。该策略可以最大化地节省CPU资源，却对内存非常不友好。
极端情况可能出现大量的过期key没有再次被访问，从而不会被清除，占用大量内存。
定期过期：每隔一定的时间，会扫描一定数量的数据库的expires字典中一定数量的key，并清除其中已过期的key。该策略是前两者的一个折中方案。
通过调整定时扫描的时间间隔和每次扫描的限定耗时，可以在不同情况下使得CPU和内存资源达到最优的平衡效果。

Redis中同时使用了惰性过期和定期过期两种过期策略。
```

##6.redis内存淘汰策略
```
Redis的内存淘汰策略
Redis的内存淘汰策略是指在Redis的用于缓存的内存不足时，怎么处理需要新写入且需要申请额外空间的数据。

noeviction：当内存不足以容纳新写入数据时，新写入操作会报错。
allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key。
allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个key。
volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的key。
volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个key。
volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的key优先移除。

```

#Ansible
##1.ansible有哪些模块；
```
ping：测试连通
file：文件创建
yum：安装
copy：复制文件
user：用户管理
shell：远程执行命令
```
##2.playbook中有哪些module；
```

```
##3.ansible你用过它的哪些模块，ansbile同时分发多台服务器的过程很慢（它是逐台分发的），你想过怎么解决吗？
```
用过ansible的（copy file yum ping command shell）等模块；ansible默认只会创建5个进程,所以一次任务只能同时控制5台机器执行.
那如果你有大量的机器需要控制,或者你希望减少进程数,那你可以采取异步执行.ansible的模块可以把task放进后台,然后轮询它.
这使得在一定进程数下能让大量需要的机器同时运作起来.
```

#Zabbix
##1.对于zabbix了解多少
```
Zabbix使用MySQL存储历史数据，所以它可以构成图表，可以查询一个月甚至一年的历史数据。Zabbix有一个自动发现的功能，当监控大批量主机的时候，可以通过这个自助发现，快速配置。所以Zabbix适合大型服务器集群的监控。
```
##2.你公司监控（如zabbix）系统监控了哪些项目。
```
监控了CPU使用率、内存剩余、磁盘使用空间、网卡流量、web服务、mysql主从、访问日志等
```
#Kubernetes
##1.谈谈对kubernetes的各个组件的理解，他们的作用？kuberproxy有哪几种实现方式？原理是什么？kubernetes的元数据是如何管理的？
##2.K8s集群你搭建过吗？用的什么方法？讲讲K8s的各个组件？在K8s集群上跑过应用吗？


#ELKStack
##1.elk中的logstash是怎么收集日志的，在客户端的logstash配置文件主要有哪些内容？
```
笔者回答：input、output两大块配置；input中指定日志（type、path）等，output指定日志输出的目标（host、port）等。
```